<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml" rel="self" type="application/atom+xml"/><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-27T23:12:54+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml</id><title type="html">Zebin Huang | JdeRobot x GSoC2024</title><subtitle>Zebin Huang | JdeRobot x GSoC2024 </subtitle><entry><title type="html">Bonding 5/21 - 5/27</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-21-5-27/" rel="alternate" type="text/html" title="Bonding 5/21 - 5/27"/><published>2024-05-26T00:00:00+00:00</published><updated>2024-05-26T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-21-5-27/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During the May 20, 2024, we discussed beginning the project by replicating last year’s model using a simple LLM for handling different input commands and gradually progressing towards more complex models. Key tasks for moving forward include conducting a literature review to define the project’s specific research question, setting up necessary tools like CARLA and behavior metrics, and addressing technical setup challenges.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="to-do-list-during-the-bonding-period">To-Do List during the bonding period</h3> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up a blog based on examples from previous years.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up CARLA.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Run Qi’s models.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Read and analyze literature on autonomous driving and LLMs.</li> </ul> <h3 id="code-replication"><strong>Code Replication</strong></h3> <p>This week, I attempted to replicate certain elements of the project codebase <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao">Meiqizhao’s code</a> and encountered some challenges that required raising issues for resolution. Specifically, I opened two issues <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/2">issue1</a> <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/3">issue2</a> and <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/pull/4">one PR</a> regarding bugs found during the replication process. To enhance reproducibility, I am currently working with Docker, and I also plan to provide a Docker branch later on.</p> <h3 id="behavior-metrics-exploration"><strong>Behavior Metrics Exploration</strong></h3> <p>I reviewed the <a href="https://github.com/JdeRobot/BehaviorMetrics">Behaviour Metrics</a> repos and related papers. The Behavior Metrics can provide a structured framework for quantifying the effectiveness and performance of autonomous system in simulated scenarios. Incorporating text input for autonomous driving guidance enhances the Behavior Metrics benchmark by interactivity and interpretability. Here are some potential integration methods and benefits:</p> <ol> <li><strong>Expanded Testing Scenarios</strong>: It enables the creation of a broader range of test environments and situations that include verbal commands and interactions.</li> <li><strong>Enhanced Textual Interpretability</strong>: Provides clarity on how the system interprets and responds to natural language inputs, which improves the system’s transparency and trustworthiness.</li> <li><strong>Adapted Interaction Methods</strong>: Allows for modifications in user interaction, offering more intuitive and accessible ways for users to communicate with autonomous systems.</li> </ol> <h3 id="literature-review-and-feasibility-analysis"><strong>Literature Review and Feasibility Analysis</strong></h3> <p>I conducted a review on research papers related to our project. The focus was on assessing the feasibility of replicating the studies, considering factors like data availability, computational requirements, and whether the methods are open-source. Such analysis helps in understanding the practical aspects of implementing these research findings in our work.</p> <table> <thead> <tr> <th>Paper Title</th> <th>Reproducibility</th> <th>Data Volume</th> <th>Technical Difficulty</th> <th>GPU Requirements</th> </tr> </thead> <tbody> <tr> <td>GPT-4V Takes the Wheel <d-cite key="huangGPT4VTakesWheel2024a"></d-cite></td> <td>Low: Uses publicly available datasets. <span style="color:red;">Not open-sourced</span></td> <td>JAAD, WiDEVIEW</td> <td>High: Integrates vision and language models for dynamic behavior prediction</td> <td>High: VLM processing but not illustrated</td> </tr> <tr> <td>Driving with LLMs <d-cite key="chenDrivingLLMsFusing2023a"></d-cite></td> <td>Low: New dataset and unique architecture, reproducibility <a href="https://github.com/wayveai/Driving-with-LLMs">GitHub</a></td> <td>Custom 160k QA pairs, 10k driving scenario. Which simulator?</td> <td>Very High: Novel fusion of vector modalities and LLMs</td> <td>Moderate: Minimum of 20GB VRAM for running evaluations, Minimum of 40GB VRAM for training</td> </tr> <tr> <td>LMDrive <d-cite key="shaoLMDriveClosedLoopEndtoEnd2023a"></d-cite></td> <td>High: Dataset and models are open-sourced, but complexity in GPU setup</td> <td><span style="color:green;">64K parsed clips and 464K notice instructions</span></td> <td>Very High: Real-time, closed-loop control with LLMs in vehicles</td> <td><span style="color:red;">Very High: 2~3 days for the visual encoder on 8x A100 (80G)</span></td> </tr> <tr> <td>Language Models as Trajectory Generators <d-cite key="kwonLanguageModelsZeroShot2023"></d-cite></td> <td>High: Standard dataset, clear methodology and evaluation process</td> <td>Flexible data generation with Pybullet</td> <td>Moderate: Focus on trajectory generation using LLMs, less complex than real-time control systems</td> <td>Low: Less demanding compared to real-time visual tasks</td> </tr> </tbody> </table> <p></p> <p>Here is a summary of the preliminary analysis of different literature pieces:</p> <ol> <li><strong>GPT-4V Takes the Wheel</strong>: This work utilizes publicly available datasets but is not open-sourced, which poses a significant barrier to reproducibility. Although it can serve as a conceptual reference, the lack of open access means it cannot be directly replicated.</li> <li><strong>Driving with LLMs</strong>: The source code is open. However, the simulator used is proprietary to Wayve, restricting access and thus full replication of the project. While the architecture and approach can be studied.</li> <li><strong>LMDrive</strong>: This project appears the most promising in terms of openness and practical usability. It is conducted on the Carla simulator platform, and pre-trained models along with the dataset are provided. Although there are no current reproducibility issues or bugs reported, the main challenge is the significant computational requirement—training requires eight A100 GPUs (80GB each). Initial testing might focus on evaluating the provided pre-trained models due to these resource demands.</li> <li><strong>Language Models as Trajectory Generators</strong>: This work offers a unique perspective by using zero-shot methods in manipulators, which is the least resource-intensive approach among the ones listed. However, for real-time systems like autonomous driving, this approach would need to incorporate more robust and safer control mechanisms to ensure reliability and safety in dynamic environments.</li> </ol> <p>From the feasibility standpoint, some of the literature reviewed indicated very high resource requirements, such as one paper necessitating 8 * A100 GPUs. These are substantial resource demands that pose challenges for replication.</p> <p>The core question we need to address is: What is our objective? If the goal is to replicate existing solutions and integration, we need to identify the features and MVP. However, if our aim is to optimize, the biggest hurdle is the training phase, particularly the GPU bottlenecks during this process. This will need to be discussed further in next week’s meeting.</p> <h3 id="moving-forward"><strong>Moving Forward</strong></h3> <p>Understanding these resource limitations and objectives will help guide our project’s direction. Our next steps involve deciding whether to seek resource optimization or to focus on adapting our goals to fit the available computational resources. Additionally, we are currently addressing several issues and plan to conduct further literature research to deepen my understanding of the field.</p> ]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Analysis of code replication and literature review]]></summary></entry><entry><title type="html">Bonding 5/15 - 5/21</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-15-5-21/" rel="alternate" type="text/html" title="Bonding 5/15 - 5/21"/><published>2024-05-24T00:00:00+00:00</published><updated>2024-05-24T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-15-5-21/"><![CDATA[<h3 id="gsoc-setting-things">GSoC Setting Things</h3> <p>Completed initial setup tasks for GSoC 2024, including payment registration, joining the Discord channel, and participating in the May 7th Contributor Summit. The summit was a great opportunity to connect with developers worldwide and gain valuable insights and tips for the program. Engaged with my mentor and community, reviewed roles and responsibilities, updated my display name, and logged meetings for future reference.</p> <h3 id="meeting-with-mentors-59">Meeting with Mentors (5/9)</h3> <p>During our first meeting, I had the opportunity to get acquainted with my mentors and discuss the project’s initial steps. Apoorv shared his journey from being a GSoC contributor to becoming a mentor at JdeRobot. David, a first-year mentor at GSoC and a PhD student, provided insights into his research on vision-based detection and drone localization.</p> <p>We discussed the technical setup for the project, including GPU access. Communication was emphasized, with Slack being the primary tool for ongoing discussions. Apoorv explained the usage of our current repository, which mainly stores documents and blogs.</p> <p>The discussion also covered the project’s initial steps, such as reviewing relevant research papers and developing a minimum viable product. Apoorv provided instructions for setting up the Carla simulator, which will be essential for our project.</p> <p>Sergio suggested starting with a simple BERT model that classifies instructions into commands, using Qi’s development from last year’s project as a starting point. We also discussed the possibility of publishing our results in a scientific paper after the summer, which added an exciting goal to our project.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <p>This document is intended to help everyone from different time zones stay on track for past meetings. It will also streamline our preparations for future meetings. I will make and review the agendas before each meeting.</p> <h4 id="to-do-list-during-the-bonding-period">To-Do List during the bonding period</h4> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up a blog based on examples from previous years.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up CARLA.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Run Qi’s models.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Read and analyze literature on autonomous driving and LLMs.</li> </ul> <h3 id="jderobot-kick-off-meeting-515">JdeRobot Kick-off Meeting (5/15)</h3> <p>In this meeting, we were welcomed to the JdeRobot GSoC program for 2024. A brief presentation about JdeRobot and its main projects was given, which helped in understanding the context and scope of the organization. Each participant, including myself, gave a quick introduction and described their project.</p> <h3 id="progress">Progress</h3> <p>Last week, I focused on setting up my blog and configuring the Carla simulator using Docker. I created the blog using Jekyll and <a href="https://github.com/alshedivat/al-folio/tree/master">al-folio</a>, referencing examples from previous years, and successfully configured the deployment workflow.</p> <p>For the Carla simulator, I opted for a Docker setup, considering I am currently primarily using servers and macOS. This choice was made to simplify the initial setup process, with plans to transition to a physical machine later. The documentation available online was quite scattered, and there were differences from the official tutorials. Hence, I plan to write a separate blog later to document this setup process in detail.</p> <p>Additionally, I have been reviewing <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao">Meiqizhao’s code</a> implementation and understanding the general ideas behind <a href="https://github.com/JdeRobot/BehaviorMetrics">behaviour metrics</a>.</p> <p>Moving forward, I will continue with the setup tasks and delve deeper into the research question to ensure a solid foundation for our project.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="GSoC,"/><category term="Weekly_blogs,"/><category term="JdeRobot"/><summary type="html"><![CDATA[Initial setup for GSoC 2024 and summary of first meetings]]></summary></entry></feed>