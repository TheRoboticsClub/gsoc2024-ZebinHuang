<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml" rel="self" type="application/atom+xml"/><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-31T13:58:06+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml</id><title type="html">Zebin Huang | JdeRobot x GSoC2024</title><subtitle>Zebin Huang | JdeRobot x GSoC2024 </subtitle><entry><title type="html">Coding week15&amp;amp;16 9/09-9/22</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1516/" rel="alternate" type="text/html" title="Coding week15&amp;amp;16 9/09-9/22"/><published>2024-09-22T00:00:00+00:00</published><updated>2024-09-22T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1516</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1516/"><![CDATA[<p>This week, we focused on exploring new ideas for enhancing autonomous vehicle capabilities with LLMs language instructions. Below is a summary of the primary ideas we considered, aiming to address current limitations and expand on innovative interaction methods between passengers and self-driving systems.</p> <p>This week, we focused on exploring new ideas for enhancing autonomous vehicle capabilities with LLMs language instructions.</p> <ul> <li> <p>Idea Selection and Planning: Sharing the complete list of ideas from this meeting and subsequent discussions will allow us to identify and finalize one or two core directions.</p> </li> <li> <p>Feasibility Research: We will also conduct feasibility studies on the selected ideas to explore technical challenges and identifying necessary tools, frameworks, and methodologies. This research will be crucial in ensuring that the chosen solutions are practically implementable for future development.</p> </li> </ul> <p>Below is a summary of the primary ideas explored.</p> <h2 id="driving-with-natural-language">Driving with Natural Language</h2> <h3 id="talk2car-taking-control-of-your-self-driving-car-">Talk2Car: Taking Control of Your Self-Driving Car <d-cite key="deruyttere_2019_Talk2CarTakingControl"></d-cite></h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week1516/talk2car-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week1516/talk2car-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week1516/talk2car-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week1516/talk2car.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>We began by exploring potential limitations from the early stages of the work.</p> <ul> <li> <p><strong>Motivation</strong>: Autonomous vehicles may hesitate in some complex traffic scenarios, especially when roads are congested or special situations arise. If passengers can provide suggestions or instructions through natural language commands, such as asking the vehicle to stop or wait, it can help the vehicle make quicker decisions.</p> </li> <li> <p><strong>Limited to Object Reference Tasks</strong>: The core issue of the article is to map the passenger’s natural language commands to specific objects in the visual scene. This “object reference” task mainly aims to enable autonomous vehicles to identify specific objects mentioned in passenger instructions, without involving direct vehicle control or executing route planning. Therefore, the article focuses solely on “recognizing reference objects”.</p> </li> <li> <p><strong>Not Involve Real Control</strong>: Although the article discusses the motivation for allowing passengers to interact with autonomous vehicles through natural language, the current research is limited to recognizing objects indicated by passengers through natural language <strong>recognition</strong> and not actually executing these instructions (e.g., stopping, turning, etc.).</p> </li> </ul> <h3 id="conditional-driving-from-natural-language-instructions-">Conditional Driving from Natural Language Instructions <d-cite key="roh20a"></d-cite></h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week1516/conditional_driving-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week1516/conditional_driving-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week1516/conditional_driving-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week1516/conditional_driving.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Previous work primarily focus on path planning and navigation systems. However, as human-machine interaction evolves, we realize that human expectations for autonomous driving systems extend beyond simple navigation commands to a more “coaching” role in interactions. In such interactions, autonomous driving systems need not only basic path planning capabilities but also the ability to understand complex, multi-turn instructions, demonstrate keen environmental insights, and effectively handle edge or hazardous scenarios. This motivation from this paper has driven the proposal and exploration of the following research directions.</p> <h3 id="talk-to-the-vehicle-language-conditioned-autonomous-navigation-of-self-driving-cars-">Talk to the Vehicle: Language-Conditioned Autonomous Navigation of Self-Driving Cars <d-cite key="sriram_2019_TalkVehicleLanguageb"></d-cite></h3> <p>The motivation for the article is based on the idea that in many complex road scenarios, traditional autonomous driving technology relies on pre-generated detailed maps and precise positioning systems. When these conditions are not met, such as when maps are inaccurate or GPS delays occur, vehicles may fail to navigate correctly.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week1516/talk2vehicle-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week1516/talk2vehicle-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week1516/talk2vehicle-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week1516/talk2vehicle.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Human navigation relies not on precise map data but on the <strong>semantic understanding of language and the current environment.</strong> By adopting this method, autonomous vehicles can navigate through semantic understanding and natural language instructions without relying on detailed offline maps.</p> <p>By introducing natural language instructions, vehicles can complete navigation tasks without accurate maps or positioning information. This reduces the dependence on external maps and GPS accuracy. This would make autonomous driving technology more robust and adaptable, especially in uncontrollable outdoor environments.</p> <p>Therefore, the research motivation is to explore how to enhance the navigation capabilities of autonomous vehicles through natural language instructions. This approach can not only improve the efficiency of autonomous driving but also allow autonomous vehicles to integrate more naturally into human driving behaviors, especially in the face of GPS positioning errors or the absence of pre-mapped maps.</p> <p>The primary inspiration for this paper is that, <strong>in real life, human drivers can easily complete navigation tasks with simple language instructions (such as “turn right at the traffic light, then turn left at the second intersection”) even without precise maps.</strong></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week1516/framework_talk2vehicle-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week1516/framework_talk2vehicle-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week1516/framework_talk2vehicle-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week1516/framework_talk2vehicle.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The framework proposed in the article has three core modules:</p> <ul> <li>NLE: Transforms natural language instructions into high-level machine-readable encodings.</li> <li>Waypoint Generation Network (WGN): Combines local semantic structure with language encoding to predict local waypoints.</li> <li>Generates obstacle-avoidance trajectories based on predicted waypoints, executed by the low-level controller.</li> <li>By combining natural language with visual and semantic maps, vehicles can generate waypoints adapted to the current environment, and this method avoids dependence on detailed maps and precise positioning. Each time local waypoints are generated, WGN considers the language instructions and the vehicle’s current environmental information.</li> </ul> <h2 id="long-turn-interaction">Long-Turn Interaction</h2> <h3 id="drivlme-enhancing-llm-based-autonomous-driving-agents-with-embodied-and-social-experiences-">DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences <d-cite key="huang__DriVLMeEnhancingLLMbased"></d-cite></h3> <p>The motivation of the article is to address the limitations of existing autonomous driving technologies in actual complex driving scenarios, especially the problems of <strong>long-duration navigation tasks</strong> and <strong>free dialogue interactions</strong>. Although current foundational models (FMs) have shown the potential to handle short-term tasks, they still face challenges when dealing with environmental dynamics, task changes, or long-term human-vehicle interactions:</p> <p>Existing autonomous driving systems are proficient at executing simple, short-term tasks like turning or overtaking but fall short when it comes to understanding broader, goal-oriented tasks that involve route planning and map knowledge. Additionally, these systems struggle to handle unexpected situations that arise from sensor limitations, environmental changes, or shifts in task requirements. Traditional systems are also limited in managing natural language dialogue, making it difficult for them to engage in complex, multi-turn interactions with passengers, especially in dynamic and evolving environments where continuous context understanding and appropriate responses are essential.</p> <h3 id="dorothie-spoken-dialogue-for-handling-unexpected-situations-in-interactive-autonomous-driving-agents-">DOROTHIE: Spoken Dialogue for Handling Unexpected Situations in Interactive Autonomous Driving Agents <d-cite key="ma_2022_DOROTHIESpokenDialogue"></d-cite></h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week1516/multi_interaction-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week1516/multi_interaction-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week1516/multi_interaction-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week1516/multi_interaction.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Motivation</strong>: User interaction with autonomous driving systems is often multi-turn, involving complex, long-duration instruction processing. To achieve this, the system must have the capability to handle long-term instructions, such as mapless navigation (Mapless Navigation) and following complex instructions (Multi-turn Interactions, Long Horizon Instructions). Traditional navigation systems only need to provide a path and execute it, but the new interaction mode requires the system to flexibly adapt to new instructions, even dynamically adjusting paths and goals during the task process.</p> <h3 id="potential-research-directions">Potential Research Directions</h3> <ol> <li> <p>Handling Ambiguity in Language Instructions: Language often contains vague or uncertain expressions, like “go forward a bit, then turn right.” Without adequate context-understanding, such vague instructions may lead to navigation errors.</p> <ul> <li>Potential research direction: Employing advanced language models (e.g., GPT series) that are better equipped to interpret ambiguous language, handle diverse expressions, and reason based on context.</li> </ul> </li> <li> <p>Semantic Understanding of Environment:</p> <p>The current system uses a waypoint generation network that combines semantic information and language encoding to produce local waypoints. However, this integration is still “static.”</p> <ul> <li>Challenges: <ul> <li>The system assumes that combining language encoding with the current semantic map suffices, but real-world scenarios often involve mismatches between environmental perception and language instructions. For instance, there could be multiple “left turns,” making it unclear which one to follow.</li> <li>While LLMs can handle complex multimodal data, the current system lacks the deeper interaction and reasoning needed to optimally use environmental and language information together.</li> </ul> </li> </ul> </li> <li> <p>Lack of Long-Term Understanding:</p> <p>Although the system’s local planning approach offers flexibility, it lacks a global perspective. Only planning local waypoints can lead to that local planning may not always find the most efficient path, potentially leading to detours or longer routes.</p> </li> <li> <p>Inadequate Exception Handling Capabilities:</p> <p>The system’s reliance on real-time sensor input and waypoint updates can make it vulnerable to unexpected situations if sensor data fails or feedback is inaccurate.</p> <ul> <li>Challenges: <ul> <li>The current system might fail to respond effectively to emergencies, such as unexpected obstacles or environmental changes.</li> <li>Although LLMs provide robust reasoning and language processing, integrating these models with dynamic environmental feedback remains limited.</li> </ul> </li> <li>Potential research direction: Investigating RL or feedback mechanisms based on historical data to help the system adjust autonomously during emergencies and dynamically optimize its path. Additionally, integrating LLMs with sensor feedback could enhance response to complex conditions.</li> </ul> </li> </ol> <h3 id="advanced-frameworks">Advanced Frameworks</h3> <ol> <li> <p>World Model Based on Real Data Research increasingly focuses on using real data to train systems for better environmental cognition, enabling systems not only to process immediate perceptual data but also to predict and anticipate complex traffic situations. This model aids in handling variable traffic scenarios, especially in dynamically changing or uncertain environments <d-cite key="guan_2024_WorldModelsAutonomous"></d-cite>.</p> </li> <li> <p>Language Generation and Embodied Experiences Language generation should go beyond preset corpora by incorporating embodied experiences. Autonomous driving systems can benefit from extracting and interpreting information from the environment and translating it into natural language feedback. In complex traffic situations, the system could assess road conditions in real-time and communicate this to users.</p> </li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[This week, we focused on exploring new ideas for enhancing autonomous vehicle capabilities with LLMs language instructions. Below is a summary of the primary ideas we considered, aiming to address current limitations and expand on innovative interaction methods between passengers and self-driving systems.]]></summary></entry><entry><title type="html">Coding week14 8/26-9/08</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week14/" rel="alternate" type="text/html" title="Coding week14 8/26-9/08"/><published>2024-09-08T00:00:00+00:00</published><updated>2024-09-08T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week14</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week14/"><![CDATA[<p>This week, we focused on exploring several potential research to create an “Ideas List”, which is a collection of possible research concepts. As we evaluate each idea in alignment with project goals, our approach includes balancing technical feasibility with anticipated resource needs and practical challenges.</p> <p>This list includes ideas focused on recent advancements, integrations with LLMs, and potential research gaps with current works. During our review, we evaluated each idea based on several key factors to identify those that promise impact while remaining feasible given our technical and resource constraints. This post outlines the main points from our discussions, along with actionable insights and next steps.</p> <h3 id="update">Update</h3> <p>In addition to our research review and ideas list development, the following updates were made:</p> <ul> <li> <p>PRs Merged into Main Branch: Two pull requests, <a href="https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang/commit/39659853cd7e4aab5a2303b6faa62d9b62cbe4ff">PR#3</a> and <a href="https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang/commit/53bf78de6a39754cbae95d118385162c82aa3d54">PR#5</a>, were successfully merged into the main branch. PR#3 focused on the model with the CARLA simulation for testing and validation, while PR#5 addressed web-based streamlit app, packaged for online deployment using the Streamlit framework.</p> </li> <li> <p>Social Media Posts: Posts were published on LinkedIn and Twitter featuring the latest video demonstration. （See <a href="https://www.linkedin.com/feed/update/urn:li:activity:7240524535718952960">LinkedIn post</a>)</p> </li> <li> <p>Documentation Update: The app documentation was revised and updated to clearly distinguish between the development version and the deployable web version.</p> </li> </ul> <iframe width="700" height="500" src="https://www.youtube.com/embed/8RdJSK0M_uc" title="GSoC24 Midterm Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="resource-availability">Resource Availability</h3> <p>We examined the viability of implementing from both technical and resource-based perspectives. This included considering our current toolset and any additional resources that may be required to bring an idea to fruition. Access to high-performance computing resources has emerged as a critical consideration, as the computational demands of the advance LLMs projects currently exceed our available resources. Given this, we are actively exploring options like using gaming GPUs, such as the RTX 4060.</p> <p>In autonomous driving model design, different architectures significantly impact GPU resource utilization. In this discussion, we use SparseDrive and LMDrive as examples to see these trade-offs in GPU resource utilization.</p> <p>The SparseDrive model achieves computational efficiency through a sparse representation framework, which minimizes reliance on dense bird’s-eye view (BEV) features, thereby reducing resource consumption, particularly in multi-GPU setups <d-cite key="sun2024sparsedrive"></d-cite>. Specifically, SparseDrive employs ResNet50 and ResNet101 backbones and train through a parallelized approach for perception and planning tasks. On an 8x NVIDIA RTX 4090 GPU system, SparseDrive demonstrates up to sevenfold increases in training and inference speeds compared to models such as UniAD <d-cite key="hu2023planning"></d-cite>, which traditionally employ dense representations. This efficiency is due to SparseDrive’s reduced floating-point operations (FLOP) requirements and decreased memory usage in its sparse, hierarchical planning structure, resulting in enhanced scalability and throughput with fewer GPU requirements <d-cite key="sun2024sparsedrive"></d-cite>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week14/sparsedrive-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week14/sparsedrive-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week14/sparsedrive-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week14/sparsedrive.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In contrast, LMDrive’s <d-cite key="shao2024lmdrive"></d-cite> architecture is more resource-intensive for closed-loop, language-guided autonomous driving. LMDrive incorporates multimodal encoders and additional adapters, such as Q-Formers and token adapters, to handle both visual and textual data inputs. This design supports the processing of extensive multi-view camera and LiDAR data and consequently increasing computational requirements relative to SparseDrive. The LLaMA-based language backbone also requires memory and processing power.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/week14/lmdrive-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/week14/lmdrive-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/week14/lmdrive-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/week14/lmdrive.png" class="img-fluid rounded z-depth-1 w-60 mx-auto d-block" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Training LMDrive requires approximately 4-6 days on 8 A100 GPUs with 80GB memory and consists of two stages: vision encoder pre-training and instruction fine-tuning, as outlined in their <a href="https://github.com/opendilab/LMDrive/blob/main/README.md#training">documentation</a>. LMDrive’s large parameter count, coupled with the need for real-time closed-loop processing, imposes a substantial load on GPU memory; however, it achieves robustness in language-guided navigation and adaptive control.</p> <h3 id="action-items">Action Items</h3> <p>To carry forward the selected ideas, we outlined specific action items. These steps are critical to ensuring that our top-priority ideas move steadily through the development pipeline. The key tasks include:</p> <ul> <li><strong>Idea Selection and Planning:</strong> Publishing the complete ideas list from this meeting and in further discussions will allow us to finalize one or two core ideas that the can focus on developing.</li> <li><strong>Feasibility Research:</strong> Comprehensive research into the technical feasibility of the selected ideas will enable us to identify specific tools, frameworks, and methodologies required for future successful implementation.</li> </ul>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[This week, we focused on exploring several potential research to create an “Ideas List”, which is a collection of possible research concepts. As we evaluate each idea in alignment with project goals, our approach includes balancing technical feasibility with anticipated resource needs and practical challenges.]]></summary></entry><entry><title type="html">Coding week12&amp;amp;13 8/12-8/25</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1213/" rel="alternate" type="text/html" title="Coding week12&amp;amp;13 8/12-8/25"/><published>2024-08-25T00:00:00+00:00</published><updated>2024-08-25T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1213</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1213/"><![CDATA[<p>In recent weeks, we have focused on enhancing model evaluation, deployment workflows, video presentation quality, and looking for next research objectives. The August 14 and 21 meetings highlighted our progress and set new goals, the meeting details are summarized in <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a>.</p> <h3 id="model-evaluation-challenges">Model Evaluation Challenges</h3> <p>In the August 14 meeting, regarding the research idea, we discussed the model’s performance in handling varied scenarios, especially focusing on collision avoidance mechanisms. Achieving high predictive accuracy remains a significant challenge, as it is essential for enhancing the model’s reliability across various simulated environments. Currently, our primary focus is on improving model accuracy through expanding the diversity of training user instruction data and scenario configurations.</p> <h3 id="model-deployment">Model Deployment</h3> <p>To address GitHub storage limitations and Hugging Face compatibility, we proposed streamlined workflows for easier updates. Key improvements include integrating OpenAI API support to simplify model loading. Next steps are to complete testing and documentation for the OpenAI API. <a href="https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang/pull/5">See PR here</a></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/api_key-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/api_key-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/api_key-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/api_key.png" class="img-fluid rounded z-depth-1 w-50" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="action-items">Action Items</h3> <p>Based on current works, the following tasks were outlined as priorities:</p> <ul> <li><strong>Immediate Fixes:</strong> Address issues in an open Pull Request on the CARLA branch, resolve Streamlit errors, integrate OpenAI API, and fix model loading challenges.</li> <li><strong>Research and Documentation:</strong> Conduct a literature review and document findings for research continuity.</li> <li><strong>Social Media Engagement:</strong> After reviewing the 1-minute demo video, it was agreed that the captions required adjustment for clarity, and background music will be added to increase appeal. Once these enhancements are complete, I will draft a LinkedIn post summarizing project achievements and outcomes to accompany the video. Draft a LinkedIn post to accompany the 1-minute demo to show recent outcomes.</li> </ul>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[In recent weeks, we have focused on enhancing model evaluation, deployment workflows, video presentation quality, and looking for next research objectives. The August 14 and 21 meetings highlighted our progress and set new goals, the meeting details are summarized in Google Doc.]]></summary></entry><entry><title type="html">Coding week10&amp;amp;11 7/29-8/11</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-29-8-11/" rel="alternate" type="text/html" title="Coding week10&amp;amp;11 7/29-8/11"/><published>2024-08-21T00:00:00+00:00</published><updated>2024-08-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1011</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-29-8-11/"><![CDATA[<p>Over the past two weeks, our focus has been on addressing several tasks for the ongoing development of our project. Here is a summary of the key action items, progress, and additional insights that have emerged during this period:</p> <ol> <li><strong>Mid-Term Evaluation</strong>: <ul> <li>We have been meticulously preparing for the mid-term evaluation, including our progress, documentation, and demos. The feedback from this evaluation will guide the next steps of our development.</li> </ul> </li> <li><strong>Fixing Video Issues in the Blog</strong>: <ul> <li>To resolve this, the video will be uploaded to a trusted platform like YouTube or Google Drive, ensuring that it is easily accessible to all viewers.</li> </ul> </li> <li><strong>Mid-Term Demo Video</strong>: <ul> <li>A critical component of our mid-term deliverables is the demonstration video showcasing the current capabilities of our model within the simulation environment. This video will highlight how the model processes and classifies different driving scenarios.</li> </ul> </li> <li><strong>Improving Dataset Evaluation</strong>: <ul> <li>We are actively exploring ways to enhance the synthetic dataset generation process, focusing on creating more diverse datasets without directly embedding commands into the instructions. The goal is to ensure that the generated data is both rich in context and relevant to our classification tasks. We are using resources such as: <ul> <li><a href="https://huggingface.co/learn/cookbook/rag_evaluation">RAG Evaluation Cookbook</a></li> <li><a href="https://huggingface.co/learn/cookbook/llm_judge">LLM Judge Evaluation Cookbook</a></li> </ul> </li> <li>These resources provide some inspiration for improving the evaluation process.</li> </ul> </li> <li><strong>Future Works</strong>: <ul> <li>As we look ahead, we are conducting a literature review to identify potential research avenues that can further enhance our project. The LMDrive repository and similar projects offer valuable insights into how we can refine our approach and explore new research ideas. We are particularly interested in extending our work to incorporate more advanced LLM techniques.</li> <li>Additionally, to show the project in action, all scripts are integrated into a web app through the Streamlit platform.</li> </ul> </li> </ol> <h3 id="streamlit-development">Streamlit Development</h3> <p>The recent development efforts have been centred on implementing a Streamlit-based app for our project. This app can make the tool more accessible and user-friendly.</p> <p><strong>Design and Architecture</strong></p> <ul> <li>The Streamlit app has been designed with a modular architecture, allowing for easy scaling and adaptation. I have already encapsulated the scripts independently, which now allows for quick splitting and building of the app through different modular pages.</li> <li>The main pages include: <ul> <li><strong>Data Generation</strong>: Users can generate datasets required for training models. This page provides the tools necessary to create diverse and robust datasets.</li> <li><strong>Data Analysis</strong>: This section allows users to analyze the generated or uploaded data. Visualization tools are integrated to help users understand the data distribution and key metrics at a glance.</li> <li><strong>Model Training</strong>: In this section, users can initiate model training sessions. The interface includes options for viewing logs and evaluating interim results. It also allows for customization of training parameters to optimize performance.</li> <li><strong>Check Logs</strong>: Users can review detailed logs from the data generation, analysis, and model training processes. This helps in debugging and ensures transparency in the operations performed by the app.</li> <li><strong>Model Testing</strong>: This page allows users to test the BERT model online with single instructions or files.</li> </ul> </li> </ul> <p><strong>Data Import/Export Interface</strong></p> <ul> <li>For online deployment, we should also implement a data import/export mechanism. Unlike the local environment, the online version requires handling real-time data flow effectively. We implemented a streamlined interface that allows users to upload data files easily and download results in various formats.</li> <li>Below is a snapshot of the code handling data import/export:</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_pdf_report</span><span class="p">(</span><span class="n">train_fig</span><span class="p">,</span> <span class="n">eval_fig</span><span class="p">,</span> <span class="n">train_log</span><span class="p">,</span> <span class="n">eval_log</span><span class="p">,</span> <span class="n">cls_report</span><span class="p">,</span> <span class="n">folder_path</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Convert logs and figures into an HTML and generate a PDF report.</span><span class="sh">"""</span>

    <span class="c1"># Convert train figure to base64
</span>    <span class="n">buffer1</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">()</span>
    <span class="n">train_fig</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">buffer1</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">buffer1</span><span class="p">.</span><span class="nf">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_base64</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">buffer1</span><span class="p">.</span><span class="nf">read</span><span class="p">()).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">train_img_html</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="sh">'</span><span class="s">&lt;img src=</span><span class="sh">"</span><span class="s">data:image/png;base64,</span><span class="si">{</span><span class="n">train_base64</span><span class="si">}</span><span class="sh">"</span><span class="s"> </span><span class="sh">'</span>
        <span class="sh">'</span><span class="s">style=</span><span class="sh">"</span><span class="s">width: 80%; max-width: 800px;</span><span class="sh">"</span><span class="s">/&gt;</span><span class="sh">'</span>
    <span class="p">)</span>

    <span class="c1"># Convert eval figure to base64
</span>    <span class="n">buffer2</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">()</span>
    <span class="n">eval_fig</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">buffer2</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">buffer2</span><span class="p">.</span><span class="nf">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">eval_base64</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">buffer2</span><span class="p">.</span><span class="nf">read</span><span class="p">()).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">eval_img_html</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="sh">'</span><span class="s">&lt;img src=</span><span class="sh">"</span><span class="s">data:image/png;base64,</span><span class="si">{</span><span class="n">eval_base64</span><span class="si">}</span><span class="sh">"</span><span class="s"> </span><span class="sh">'</span>
        <span class="sh">'</span><span class="s">style=</span><span class="sh">"</span><span class="s">width: 80%; max-width: 800px;</span><span class="sh">"</span><span class="s">/&gt;</span><span class="sh">'</span>
    <span class="p">)</span>

    <span class="c1"># Generate markdown for logs
</span>    <span class="n">train_log_md</span><span class="p">,</span> <span class="n">eval_log_md</span><span class="p">,</span> <span class="n">cls_report_md</span> <span class="o">=</span> <span class="nf">generate_markdown</span><span class="p">(</span>
        <span class="n">train_log</span><span class="p">,</span> <span class="n">eval_log</span><span class="p">,</span> <span class="n">cls_report</span>
    <span class="p">)</span>
    <span class="n">train_html</span><span class="p">,</span> <span class="n">eval_html</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">train_log_md</span><span class="p">),</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">eval_log_md</span><span class="p">),</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">cls_report_md</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Create HTML content
</span>    <span class="n">html_content</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Markdown&lt;/title&gt;
        &lt;style&gt;
            body 
            img 
            .page-break 
        &lt;/style&gt;
    &lt;/head&gt;
    &lt;body&gt;
        </span><span class="si">{</span><span class="n">train_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">train_img_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">eval_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">eval_img_html</span><span class="si">}</span><span class="s">

    &lt;/body&gt;
    &lt;/html&gt;
    </span><span class="sh">"""</span>

    <span class="c1"># Convert HTML to PDF
</span>    <span class="n">pdf_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">folder_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">logs_report.pdf</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">convert_html_to_pdf</span><span class="p">(</span><span class="n">html_content</span><span class="p">,</span> <span class="n">pdf_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pdf_path</span>
</code></pre></div></div> <p><strong>Challenges in Model Storage</strong></p> <ul> <li>A significant technical challenge was how to manage the storage and export of models trained online. Given the constraints of bandwidth and storage, exporting large models like BERT is not feasible within our current setup. Therefore, we opted for TinyBERT, a more compact model that has shown excellent performance in our tests, achieving nearly 100% accuracy in the scenarios we’ve evaluated.</li> <li>Referring to this article <a href="https://blog.streamlit.io/common-app-problems-resource-limits/">here</a>, Streamlit currently has resource limitations, which prevent us from freely training and exporting pre-trained models. This feature in our app is not yet fully supported. We are considering using Github’s Large File Storage, but this solution has not been fully tested yet.</li> </ul> <h3 id="llm-evaluation"><strong>LLM Evaluation</strong></h3> <p>In addition to implementing the Streamlit app, we have been exploring various cookbooks from Hugging Face suggested by mentors to refine our approach. However, this exploration has also revealed several challenges:</p> <ol> <li><strong>Sample Size Insufficiency</strong>: The current dataset might not be large enough to fully train more complex models. We are considering various data augmentation strategies to increase the dataset’s size and diversity.</li> <li><strong>Evaluation of Human Input</strong>: The evaluation methods we currently use are heavily reliant on human judgment. To address this, we are exploring automated evaluation techniques that can provide consistent and scalable assessments.</li> <li><strong>Lack of Trials</strong>: The limited availability of real-world data and trials has been a bottleneck. To overcome this, some self-supervised methods should be explored.</li> </ol> <h3 id="model-inference">Model Inference</h3> <p>We conducted a series of comparative experiments to determine whether the model inference stage significantly impacts decision-making within the simulation. Our findings indicate that the model’s decisions remain consistent, even under varied conditions.</p> <p>Interestingly, we discovered that some collision issues initially thought to be caused by the model inference stage, were actually rooted in problems with the previous model version. To provide more insight, we have attached both error videos and examples of correct simulations.</p> <iframe width="700" height="500" src="https://www.youtube.com/embed/1Fg6R5mZLHE" title="Control with bert" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <iframe width="700" height="500" src="https://www.youtube.com/embed/urk-g_el_gg" title="Crash without bert" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="next-steps">Next Steps</h3> <p>I have prepared a mid-term summary video, which will be submitted for feedback. This video summarizes the current status of the project. Based on the feedback received, we will make the necessary adjustments to ensure that the project continues to meet its objectives and align with the broader goals of the GSoC initiative.</p> <p>Moving forward, we will delve deeper into the literature, exploring new research directions that could lead to improvements in the model’s performance and its integration within the CARLA simulation environment.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Over the past two weeks, our focus has been on addressing several tasks for the ongoing development of our project. Here is a summary of the key action items, progress, and additional insights that have emerged during this period:]]></summary></entry><entry><title type="html">Coding week8 7/15-7/21</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-15-7-21/" rel="alternate" type="text/html" title="Coding week8 7/15-7/21"/><published>2024-07-21T00:00:00+00:00</published><updated>2024-07-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week8</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-15-7-21/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During this week’s meeting, the team discussed several key updates and future plans. Sergio and Apoorv reminded me to provide weekly updates on the project blog to track progress and evaluation. I recapped the data generation process, highlighting issues with high duplication and the implementation of strategies like dynamic batch size and the iterative method, which improved speed by 28%. However, scalability issues were noted. I also discussed the high-level command design for the demo, simulator installation challenges, and the retraining of the BERT model, which achieved 100% accuracy with 300 samples. Environmental issues were addressed, but data collection and iteration interruptions remained problematic. In the open floor discussion, the team explored future directions, such as using world models or simulators to improve data efficiency and considering external datasets. Sergio outlined the next steps, including integrating the new BERT model into the pipeline, publishing code and results, and potentially developing a Streamlit demo app.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="setting-up-carla-with-a-graphical-interface">Setting Up CARLA with a Graphical Interface</h3> <p>Because we have been developing CARLA within Docker, setting up a graphical interface is essential for better visualization and simulation. This week, I attempted to establish this environment, initially assuming it would be relatively straightforward. However, this task proved to be quite time-consuming.</p> <p>CARLA Basic Hardware Requirements</p> <p>Before diving into the setup process, it is crucial to understand the basic hardware requirements for running CARLA smoothly:</p> <ul> <li>CPU: Intel i5-8600k or higher</li> <li>GPU: NVIDIA GeForce GTX 1080 or equivalent</li> <li>RAM: 16 GB</li> <li>Storage: SSD with at least 50 GB of free space</li> <li>Operating System: Ubuntu 18.04/20.04 or Windows 10/Server 2019</li> </ul> <p>Initially, I planned to set up CARLA on headless servers. Here’s a summary of the challenges faced:</p> <p><strong>Windows Server 2019</strong>: The setup on a Windows Server 2019 system was expected to be straightforward. However, this older system caused numerous issues, leading to persistent errors as shown in the image below. These errors were likely due to compatibility issues with the older Windows version.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/win_error-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/win_error-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/win_error-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/win_error.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Ubuntu Server</strong>: Another attempt was made on an Ubuntu server. Unfortunately, due to being on a university’s internal network, port restrictions prevented the use of VNC for desktop access. This limitation made it challenging to run CARLA with a graphical interface.</p> <p>Given these challenges, the only viable option was to run CARLA on a physical desktop machine. This approach allowed me to bypass the issues encountered with headless servers and internal network restrictions. Finally, here is a video of the trained model running on CARLA:</p> <iframe width="700" height="500" src="https://www.youtube.com/embed/1FJVz80yBFQ" title="Carla_deployment_test" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="model-training-and-optimization">Model Training and Optimization</h3> <p>Over the past week, several improvements have been made to our model in performance and flexibility. These updates include:</p> <ol> <li> <p><strong>Training with a New Dataset</strong>: The model was retrained using a new and more comprehensive dataset, which led to an improvement in prediction accuracy. The retraining process resulted in the model achieving nearly 100% accuracy, demonstrating the effectiveness of the new data.</p> </li> <li> <p><strong>Model Size Optimization</strong>: To optimize performance and resource usage, different versions of the model were tested, including <code class="language-plaintext highlighter-rouge">bert_model</code>, <code class="language-plaintext highlighter-rouge">distilbert_model</code>, and <code class="language-plaintext highlighter-rouge">tinybert_model</code>. Each version showed significant differences in terms of speed and memory consumption. Despite these differences, all versions maintained a high level of accuracy. This experimentation highlights the potential for deploying smaller, more efficient models without compromising on performance.</p> </li> <li> <p><strong>Code Refactoring</strong>: The codebase underwent extensive refactoring to improve maintainability. The model-related code was updated to fully accept parameters. Additionally, new testing interfaces were implemented, which enable both single instruction inputs and file-based inputs. These interfaces facilitate more testing and validation of the model under various scenarios.</p> </li> </ol> <p>These improvements enhance the model’s robustness, efficiency, and adaptability.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">-rw-r--r--</span>  1 zebin  staff   418M Jul 24 06:59 bert_model.pt
<span class="nt">-rw-r--r--</span>  1 zebin  staff   255M Jul 24 06:38 distilbert_model.pt
<span class="nt">-rw-r--r--</span>  1 zebin  staff    55M Jul 24 07:14 tinybert_model.pt
</code></pre></div></div> <h2 id="model-integration">Model integration</h2> <p>To independently verify that the LLM language module is functioning correctly, a <code class="language-plaintext highlighter-rouge">config_translator</code> was created. This tool uses the GPT interface to generate instructions based on some predefined actions found in the <code class="language-plaintext highlighter-rouge">test_suites</code>. Below are the generation results for <code class="language-plaintext highlighter-rouge">Town02_All.txt</code>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/test_suite-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/test_suite-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/test_suite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/test_suite.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Two online testing methods for the model were established. One method involves testing through a single instruction, while the other involves testing through a configuration data file. Below are the model prediction results for <code class="language-plaintext highlighter-rouge">Town02_All.txt</code> (the last two actions on the right are model predictions). As you can see, the results are consistent.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/pred_test_suite-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/pred_test_suite-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/pred_test_suite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/pred_test_suite.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="code-refactoring">Code Refactoring</h3> <p>Recent efforts in code refactoring have focused on improving robustness, flexibility, and maintainability. Here are the key improvements:</p> <ol> <li>Exception Handling: We have implemented exception handling across the codebase to manage potential errors more effectively. This includes: <ul> <li>Invalid Configuration Formats: Ensuring that the system gracefully handles incorrect or malformed configuration files.</li> <li>Invalid Actions: Adding checks to handle scenarios where actions specified are not recognized or are outside the expected range.</li> <li>Non-existent Directories: Implementing safeguards to manage cases where required directories are missing.</li> </ul> </li> <li> <p>Parameterization: All scripts have been fully parameterized, enhancing their flexibility and ease of use. Parameterization allows users to adjust script behavior without modifying the underlying code, facilitating.</p> </li> <li>Configuration File and Utilities: To further improve code maintainability, we have introduced an independent configuration file and a set of utility functions: <ul> <li>Configuration File: Centralizes all configuration settings, making it easier to manage and update system-wide settings in one place. This separation of configuration from code simplifies adjustments and reduces the risk of errors.</li> <li>Utility Functions (<code class="language-plaintext highlighter-rouge">utils</code>): A dedicated set of utility functions has been created to handle common tasks and operations. Common operations are abstracted into these utility functions, which can be easily called from different parts of the project.</li> </ul> </li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week9 7/22-7/28</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-22-7-28/" rel="alternate" type="text/html" title="Coding week9 7/22-7/28"/><published>2024-07-21T00:00:00+00:00</published><updated>2024-07-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week9</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-22-7-28/"><![CDATA[<p>This blog post serves as a comprehensive update on our progress, challenges, and future plans, providing a clear picture of where the project stands and where it is headed. We look forward to the next phase of development.</p> <h3 id="introduction">Introduction</h3> <p>This project aims to advance the intersection of Large Language Models (LLMs) and autonomous driving simulation. To better understand the architecture of this project, let’s take a closer look at the project’s overall framework. This framework illustrates the workflow, starting with the generation of synthetic data through LLMs, followed by training a BERT model with this data. Finally, the trained model is integrated into the CARLA simulator.</p> <p>The project is divided into two distinct yet interconnected parts:</p> <ol> <li><strong>Data Generation and BERT Model Training</strong>: The initial phase involves leveraging LLMs to generate diverse scalable datasets. These datasets are then used to train a BERT series model for specific classification tasks related to autonomous driving scenarios.</li> <li><strong>CARLA Simulation</strong>: The second phase focuses on integrating the trained BERT model into the CARLA simulator. This integration is designed to enhance the simulation’s ability to classify and respond to various human instructions, thereby improving the overall decision-making process.</li> </ol> <h3 id="video-demo">Video Demo</h3> <p>As part of the mid-term deliverable, a video demonstrating the project’s current capabilities has been prepared. This video showcases how the BERT model, trained with LLM-generated data, functions within the CARLA simulator.</p> <p><a href="https://gsoc24-zebinhuang.streamlit.app/"><img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg" alt="Streamlit App"/></a></p> <iframe width="700" height="500" src="https://www.youtube.com/embed/bigQi9wnrdY" title="GSoC24 Midterm Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="challenges">Challenges</h3> <p>Throughout the development process, several significant challenges were encountered, particularly in the following areas:</p> <ol> <li><strong>Performance and Reliability of Data Generation</strong>: One of the core challenges was ensuring that the data generated by the LLMs was both relevant and diverse enough to effectively train the BERT model. The quality of this synthetic data directly impacts the model’s performance, making it crucial to address issues related to data generation reliability and efficiency.</li> <li><strong>Integration of BERT with CARLA</strong>: While the integration of the BERT model into the CARLA simulator marks a significant step forward, it was noted that the integration was not as seamless as desired. The classifier model, trained using LLM-generated data, currently operates somewhat independently of the broader autonomous driving system. As a result, the full potential of the LLM in enhancing the CARLA simulation has not yet been fully realized. For information on how to integrate models into CARLA, check out this <a href="https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang/pull/3">PR</a>.</li> </ol> <h3 id="limitations-and-future-works">Limitations and Future Works</h3> <p>Despite the progress made, the project has several limitations that need to be addressed in future iterations:</p> <ol> <li><strong>Limited Integration of LLM</strong>: The current integration between the LLM-generated data and the CARLA simulator is not fully optimized. The BERT model functions as a standalone classifier rather than being deeply embedded within the autonomous driving system. This limits the overall impact of the LLM on the simulation’s performance. This would involve developing methods to enable real-time scenario understanding and decision-making within the simulator, leveraging the strengths of both LLMs and autonomous driving technologies.</li> <li><strong>Quality Evaluation of Datasets</strong>: The project has primarily focused on the generation of synthetic data. However, the evaluation of this data’s quality remains an area that requires further exploration. Future work will need to develop self-supervised evaluation methods that can assess data quality without human intervention. These techniques would allow for automated, scalable assessments of synthetic data, improving the overall reliability and effectiveness of the training datasets.</li> <li><strong>Bridging the Sim2Real Gap</strong>: Another key area of research could involve bridging the gap between simulated data and real-world driving data. This would involve refining the synthetic data generation process to more closely mirror real-world conditions, thus making the models trained on this data more applicable to real-world autonomous driving scenarios.</li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[This blog post serves as a comprehensive update on our progress, challenges, and future plans, providing a clear picture of where the project stands and where it is headed. We look forward to the next phase of development.]]></summary></entry><entry><title type="html">Coding week7 7/08-7/14</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week7-7-08-7-14/" rel="alternate" type="text/html" title="Coding week7 7/08-7/14"/><published>2024-07-14T00:00:00+00:00</published><updated>2024-07-14T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week7</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week7-7-08-7-14/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During the July 10 meeting, we focused on refining our dataset and integrating our models into the overall framework. We discussed the use of iterative generation techniques to remove duplicated lines from our datasets, aiming to establish a robust baseline for our project. We also explored the implementation of high-level commands with text inputs for the model.</p> <p>Two key questions were raised during the meeting:</p> <ul> <li>Route Selection: If there is no predefined route, the function <code class="language-plaintext highlighter-rouge">get_random_hlc</code> will randomly select a command. This method needs further clarification to ensure it aligns with our overall approach.</li> <li>Instruction Classification: There was a discussion on the necessity of predefined data for classification purposes. Despite having the ground truth, the reason for classifying predefined data needs further elaboration to ensure it enhances the model’s performance effectively. These discussions and clarifications are crucial as we integrate the model into the framework, moving towards our project’s first baseline.</li> </ul> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="data-generation-performance-optimization">Data Generation Performance Optimization</h3> <p>Recently, the focus has been on optimizing the performance of data generation. In previous work, it was noticeable that calling the API consumed a significant amount of time. Here is a potential analysis of the reasons for the slowness, which may involve two situations:</p> <ol> <li>The number of parallel requests is too small, resulting in request limitations.</li> <li>Each call requires a long return time.</li> </ol> <h3 id="api-rate-limits">API Rate Limits</h3> <p>I checked the <a href="https://platform.openai.com/docs/guides/rate-limits">GPT documentation</a> and found the following notes on rate limits.</p> <p><em>Rate limits</em></p> <p><em>Rate limits are restrictions that our API imposes on the number of times a user or client can access our services within a specified period of time.</em></p> <p><em>How do these rate limits work?</em></p> <p><em>Rate limits are measured in five ways: <strong>RPM</strong> (requests per minute), <strong>RPD</strong> (requests per day), <strong>TPM</strong> (tokens per minute), <strong>TPD</strong> (tokens per day), and <strong>IPM</strong> (images per minute). Rate limits can be hit across any of the options depending on what occurs first. For example, you might send 20 requests with only 100 tokens to the ChatCompletions endpoint and that would fill your limit (if your RPM was 20), even if you did not send 150k tokens (if your TPM limit was 150k) within those 20 requests.</em></p> <p>OpenAI calculates different rates based on different prepayment levels. Currently, my account is at Tier 2. As observed, even within Tier 2, GPT-3.5-turbo is faster than GPT-4. This means there are more parallel requests available. Therefore, the performance bottleneck should mainly be in point 2: <strong>each call requires a long return time</strong>. I speculate that the performance bottleneck is likely due to the time taken for each request’s model inference and the network latency.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/rate_limit-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/rate_limit-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/rate_limit-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/rate_limit.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="how-can-we-reduce-the-number-of-calls">How can we reduce the number of calls?</h3> <p>In the original code, instructions generation was done one by one, meaning each time a command was generated, an API call was made. Even with the Batch method, the implementation of this batch method does not reduce <strong>the number of API calls</strong>.</p> <p>This method becomes very slow when a large number of commands need to be generated because each API call incurs network latency and processing time. Additionally, if the generated commands are duplicated, they need to be regenerated, further increasing the time consumption.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/batch-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/batch-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/batch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/batch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To improve the speed of command generation, we have adopted the following two main optimization methods:</p> <ol> <li>Batch Generation with One-time Request: One-time request can reduce the number of API calls, thereby reducing the overhead of network latency and processing time for each call. <ul> <li>Implementation: By using the <code class="language-plaintext highlighter-rouge">n</code> parameter of the <code class="language-plaintext highlighter-rouge">openai.chat.completions.create</code> method, multiple commands can be generated at once. For example, a single API call can generate 5 commands instead of making 5 separate calls to generate 1 command each time.</li> <li>Prompt: Currently, the prompt can only generate one command at a time. Modifying it to generate <code class="language-plaintext highlighter-rouge">batch_size</code> commands at once can significantly reduce the number of API calls.</li> </ul> </li> </ol> <p>Original prompt:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_instruction_prompt</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate a prompt for the OpenAI API to create a driving instruction for a given action.
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    Generate a short driving instruction that includes the action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">. Here are three examples:
    1. </span><span class="sh">"</span><span class="s">Turn right at the next intersection.</span><span class="sh">"</span><span class="s">
    2. </span><span class="sh">"</span><span class="s">Go straight past the traffic light.</span><span class="sh">"</span><span class="s">
    3. </span><span class="sh">"</span><span class="s">Merge into the left lane.</span><span class="sh">"</span><span class="s">
    Generate an instruction that includes </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">:
    </span><span class="sh">"""</span>
</code></pre></div></div> <p>New prompt for multiple instructions:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_instruction_prompt</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate a prompt for the OpenAI API to create a driving instruction for a given action.
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    Generate a short driving instruction that includes the action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">.
    Make sure each instruction is distinct and uses different wording or context. Here are some examples:
    </span><span class="sh">"</span><span class="s">Turn right at the next intersection.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Go straight past the traffic light.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Merge into the left lane.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">At the roundabout, take the second exit.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Keep left to stay on the main road.</span><span class="sh">"</span><span class="s">
    There does not need to be any numerical numbering or any prefixes.
    Generate </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s"> unique instruction that include </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">:
    </span><span class="sh">"""</span>
</code></pre></div></div> <p>After testing, we found that the new prompt can significantly reduce the data generation time and there are almost no duplicate commands. This suggests that to generate data with similar structures, a more effective way to increase speed and avoid duplication is to generate a large batch of data at the prompt stage.</p> <h3 id="parallel-processing">Parallel Processing</h3> <p>Besides reducing the number of API calls, another method is to fully utilize the current Tier 2 parallel potential. Given the 3500 RPM of GPT-3.5-turbo, there is still more room for parallel processing. Parallel processing can fully utilize the capabilities of multi-core CPUs, reducing the overall processing time. Especially in network I/O intensive operations such as API calls, parallel processing can significantly reduce waiting time.</p> <p>By using <code class="language-plaintext highlighter-rouge">concurrent.futures.ThreadPoolExecutor</code>, parallel processing is achieved.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/optimized-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/optimized-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/optimized-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/optimized.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the optimized code, we combined the two methods mentioned above: using batch generation to reduce the number of API calls and using parallel processing to handle multiple batch generation requests simultaneously. The specific implementation steps are as follows:</p> <p><strong>Batch Generation of Commands:</strong></p> <p>Using the latest prompt mentioned above and passing in the <code class="language-plaintext highlighter-rouge">batch_size</code> parameter to generate multiple instructions at once. It is important to note that more tokens are needed (<code class="language-plaintext highlighter-rouge">max_tokens=10</code> in our case), and regular expressions should be used to handle any potential impurities in the data. For example, data entries like these: ”43. Proceed straight towards the tall building in the distance.“ or ”- Travel straight as the road bends to the left.” The following regex code can effectively remove impurities:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1"># Split multiple instructions from a single response
</span>    <span class="n">instructions</span> <span class="o">=</span> <span class="n">raw_instruction</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Remove leading numbers and punctuation from each instruction
</span>    <span class="n">instructions_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">^[\d\W]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">instruction</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">instruction</span> <span class="ow">in</span> <span class="n">instructions</span>
    <span class="p">]</span>
</code></pre></div></div> <p>In the <code class="language-plaintext highlighter-rouge">fetch_instructions</code> and <code class="language-plaintext highlighter-rouge">generate_instructions_batch</code> functions in <code class="language-plaintext highlighter-rouge">utils.py</code>, use the <code class="language-plaintext highlighter-rouge">n</code> parameter to generate multiple commands at once. This method was later removed because the prompt itself can generate a sufficient number of instructions.</p> <p><strong>Thread Pool:</strong></p> <p>In the <code class="language-plaintext highlighter-rouge">generate_dataset</code> function in <code class="language-plaintext highlighter-rouge">dataset_generator.py</code>, use <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> to parallelize the execution of multiple batch generation requests.</p> <p><code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> is used to manage concurrent tasks, where each task generates a batch of instructions for a given action. It ensures that a unique set of instructions is generated for each action, dynamically adjusting the batch size to ensure at least five samples per batch while not exceeding the maximum batch size. The tasks are submitted to the <code class="language-plaintext highlighter-rouge">executor</code>, and the future results are mapped to their respective actions for further processing.</p> <p>By default, <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> automatically determines the number of threads based on the system’s available resources. However, we can control the number of concurrent tasks more precisely by setting the thread pool size. If not specified, <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> will use a reasonable default value, usually <code class="language-plaintext highlighter-rouge">os.cpu_count()</code>.</p> <p>In addition to the core points mentioned above, there are other techniques that can be adopted.</p> <ol> <li><em>Reduce output token count</em></li> <li><em>Switch from GPT-4 to GPT-3.5</em></li> <li><em>Switch to Azure-hosted APIs</em></li> <li><em>Parallelize your calls</em></li> <li><em>Stream output and use stop sequences</em></li> </ol> <p>For more detailed information, you can refer to this blog: <a href="https://www.taivo.ai/__making-gpt-api-responses-faster/">Making GPT API Responses Faster</a></p> <p>Because the data structures we use are relatively simple, it’s easy to reduce the token count, and using GPT-3.5 is more cost-effective and faster.</p> <p>We used optimized methods to recreate the data and tested the generation efficiency under different conditions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="n">dataset_generator_batch_optimized</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">actions</span> <span class="n">Straight</span> <span class="n">Right</span> <span class="n">LaneFollow</span> <span class="n">Left</span> <span class="o">--</span><span class="n">num_samples</span> <span class="mi">1000</span> <span class="o">--</span><span class="n">output_file</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">user_instructions</span><span class="o">/</span><span class="n">dataset_4000</span><span class="p">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">100</span>
</code></pre></div></div> <table> <thead> <tr> <th>Instructions Generated</th> <th>Time (seconds)</th> </tr> </thead> <tbody> <tr> <td>500</td> <td>26.09</td> </tr> <tr> <td>1000</td> <td>44.97</td> </tr> <tr> <td>4000</td> <td>159.67</td> </tr> </tbody> </table> <p>In the previous method, generating 100 instructions took 158.48 seconds, and the data set stopped growing around 1k. With the new method, this limit can be easily surpassed, and the time to generate data has been significantly reduced.</p> <p>Here is the complete terminal output log for <code class="language-plaintext highlighter-rouge">dataset_4000.csv</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="n">dataset_generator_batch_optimized</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">actions</span> <span class="n">Straight</span> <span class="n">Right</span> <span class="n">LaneFollow</span> <span class="n">Left</span> <span class="o">--</span><span class="n">num_samples</span> <span class="mi">1000</span> <span class="o">--</span><span class="n">output_file</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">user_instructions</span><span class="o">/</span><span class="n">dataset_4000</span><span class="p">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">94</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">94</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">60</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">40</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">84</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">167</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">27</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">184</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">167</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">144</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">250</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">271</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">13</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">228</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">252</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">338</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">336</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">305</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">348</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">439</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">9</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">434</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">4</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">419</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">394</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">11</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">522</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">502</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">524</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">472</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">22</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">607</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">595</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">29</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">577</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">25</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">555</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">688</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">7</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">699</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">8</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">661</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">637</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">747</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">782</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">706</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">31</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">785</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">875</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">783</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">830</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">855</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">27</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">945</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">915</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">862</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">21</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">957</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">86</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1019</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">12</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">86</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1036</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">7</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1003</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">12</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">944</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1075</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">25</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1026</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Total</span> <span class="nf">discarded </span><span class="p">(</span><span class="n">duplicate</span><span class="p">)</span> <span class="n">instructions</span><span class="p">:</span> <span class="mi">813</span>
                                            <span class="n">instruction</span>      <span class="n">action</span>
<span class="mi">0</span>                                                    <span class="sh">""</span>  <span class="p">[</span><span class="n">Straight</span><span class="p">]</span>
<span class="mi">1</span>     <span class="sh">"</span><span class="s">Continue straight on this route until you see...  [Straight]
2             </span><span class="sh">"</span><span class="n">Go</span> <span class="n">straight</span> <span class="n">onto</span> <span class="n">the</span> <span class="n">highway</span> <span class="nb">exit</span> <span class="n">ramp</span><span class="p">.</span><span class="sh">"</span><span class="s">  [Straight]
3                    </span><span class="sh">"</span><span class="n">Head</span> <span class="n">straight</span> <span class="n">along</span> <span class="n">this</span> <span class="n">avenue</span><span class="p">.</span><span class="sh">"</span><span class="s">  [Straight]
4     </span><span class="sh">"</span><span class="n">Navigate</span> <span class="n">the</span> <span class="n">roundabout</span> <span class="ow">and</span> <span class="n">take</span> <span class="n">the</span> <span class="nb">exit</span> <span class="nb">str</span><span class="p">...</span>  <span class="p">[</span><span class="n">Straight</span><span class="p">]</span>
<span class="p">...</span>                                                 <span class="p">...</span>         <span class="bp">...</span>
<span class="mi">3995</span>  <span class="sh">"</span><span class="s">Watch for any obstructions on the left side o...      [Left]
3996               </span><span class="sh">"</span><span class="n">Signal</span> <span class="n">left</span> <span class="n">before</span> <span class="n">changing</span> <span class="n">lanes</span><span class="p">.</span><span class="sh">"</span><span class="s">      [Left]
3997              </span><span class="sh">"</span><span class="n">Stay</span> <span class="n">left</span> <span class="n">to</span> <span class="n">enter</span> <span class="n">the</span> <span class="n">parking</span> <span class="n">lot</span><span class="p">.</span><span class="sh">"</span><span class="s">      [Left]
3998  </span><span class="sh">"</span><span class="n">Merge</span> <span class="n">into</span> <span class="n">the</span> <span class="n">left</span> <span class="n">lane</span> <span class="k">for</span> <span class="n">the</span> <span class="n">upcoming</span> <span class="n">lef</span><span class="p">...</span>      <span class="p">[</span><span class="n">Left</span><span class="p">]</span>
<span class="mi">3999</span>              <span class="sh">"</span><span class="s">Proceed left at the T-intersection.</span><span class="sh">"</span>      <span class="p">[</span><span class="n">Left</span><span class="p">]</span>

<span class="p">[</span><span class="mi">4000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">2</span> <span class="n">columns</span><span class="p">]</span>
<span class="n">Dataset</span> <span class="n">generated</span> <span class="ow">and</span> <span class="n">saved</span> <span class="n">to</span> <span class="sh">'</span><span class="s">./datasets/user_instructions/dataset_4000.csv</span><span class="sh">'</span>
<span class="n">Generated</span> <span class="mi">4000</span> <span class="n">instructions</span> <span class="ow">in</span> <span class="mf">159.67</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div> <p>Word cloud map analysis of the dataset</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/word_cloud_714-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/word_cloud_714-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/word_cloud_714-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/word_cloud_714.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="conclusion">Conclusion</h3> <p>For generating similar types of instruction data, a more efficient approach is:</p> <ul> <li>Deduplication: Instruct the model to generate multiple unique pieces of data in a single prompt, rather than using the same prompt multiple times and then deduplicating, as this does not improve the quality of the data.</li> <li>Acceleration: Reduce the number of requests, increase the amount generated per request, and use parallel processing.</li> </ul> <p>The above test results are based on a not fully optimized setup. I believe further optimization is possible. This method is scalable in terms of data. Regarding performance, one of the biggest impacts is <code class="language-plaintext highlighter-rouge">num_threads</code>; I currently use around 10. Additionally, for <code class="language-plaintext highlighter-rouge">max_batch_size</code>, I generally use 100.</p> <p>It is also worth noting that the development cost is relatively affordable. Throughout the entire development cycle, my API usage bill did not exceed $10.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/api_usage-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/api_usage-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/api_usage-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/api_usage.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting During the July 10 meeting, we focused on refining our dataset and integrating our models into the overall framework. We discussed the use of iterative generation techniques to remove duplicated lines from our datasets, aiming to establish a robust baseline for our project. We also explored the implementation of high-level commands with text inputs for the model.]]></summary></entry><entry><title type="html">Coding week6 7/01-7/07</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-7-01-7-07/" rel="alternate" type="text/html" title="Coding week6 7/01-7/07"/><published>2024-07-07T00:00:00+00:00</published><updated>2024-07-07T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week6</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-7-01-7-07/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>Our follow-up meeting on June 26 continued addressing critical issues. I led a discussion on unbalanced datasets and implemented simple and complex instructions. We explored the use of a BERT model for instruction classification, agreeing on the importance of dividing datasets into training and testing sets to ensure robust metrics. A key outcome was removing duplicated lines from datasets using iterative generation techniques. We plan to integrate the BERT model with the refined dataset and incorporate it into the overall framework to establish our first baseline. Sergio proposed two approaches: utilizing Qi’s model for action decoding and aiming towards a step forward with the LMDrive model.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="sample-route">Sample Route</h3> <p>The <code class="language-plaintext highlighter-rouge">sample_route</code> function randomly selects a route from the provided <code class="language-plaintext highlighter-rouge">episode_configs</code> file. Let’s break down this function step by step to understand how the route is generated and what it contains.</p> <p>First, let’s look at the code for the <code class="language-plaintext highlighter-rouge">sample_route</code> function:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sample_route</span><span class="p">(</span><span class="n">world</span><span class="p">,</span> <span class="n">episode_configs</span><span class="p">):</span>
    <span class="n">spawn_points</span> <span class="o">=</span> <span class="n">world</span><span class="p">.</span><span class="nf">get_map</span><span class="p">().</span><span class="nf">get_spawn_points</span><span class="p">()</span>
    <span class="n">episode_config</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">episode_configs</span><span class="p">)</span>
    <span class="n">start_point</span> <span class="o">=</span> <span class="n">spawn_points</span><span class="p">[</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">end_point</span> <span class="o">=</span> <span class="n">spawn_points</span><span class="p">[</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">from spawn point #</span><span class="si">{</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s"> to #</span><span class="si">{</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">route_length</span> <span class="o">=</span> <span class="n">episode_config</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">route</span> <span class="o">=</span> <span class="n">episode_config</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">episode_config</span><span class="p">,</span> <span class="n">start_point</span><span class="p">,</span> <span class="n">end_point</span><span class="p">,</span> <span class="n">route_length</span><span class="p">,</span> <span class="n">route</span>
</code></pre></div></div> <p>The given <code class="language-plaintext highlighter-rouge">episode_configs</code> file contains multiple lines of data, each representing a route and its associated high-level commands. Each line follows this format:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start Index End Index Route Length High-Level Command1 High-Level Command2
</code></pre></div></div> <p>For example, the first line of data is:</p> <div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">24</span> <span class="err">79</span> <span class="err">158</span> <span class="nt">Right</span> <span class="nt">Right</span>
</code></pre></div></div> <p>This means:</p> <ul> <li>Start Index: 24</li> <li>End Index: 79</li> <li>Route Length: 158</li> <li>High-Level Commands: Right, Right</li> </ul> <h3 id="contents-of-the-route">Contents of the <code class="language-plaintext highlighter-rouge">route</code></h3> <p>The <code class="language-plaintext highlighter-rouge">route</code> contains a series of high-level commands, which are the vehicle’s turning instructions at intersections along the route. For example, the <code class="language-plaintext highlighter-rouge">route</code> value might be <code class="language-plaintext highlighter-rouge">['Right', 'Right']</code>, indicating that the vehicle should turn right at the first intersection and right again at the second intersection.</p> <p>In the subsequent simulation process, these return values will be used to initialize the vehicle’s position, determine its travel route, and guide the vehicle’s turns at intersections through high-level commands.</p> <h3 id="why-use-imitation-learning">Why Use Imitation Learning?</h3> <p>In the paper “End-to-end Driving via Conditional Imitation Learning,” the authors address the limitations and challenges of imitation learning for autonomous urban driving. The primary motivation for this work is to overcome the inherent difficulties in mapping perceptual inputs directly to control commands, especially in complex driving scenarios.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/imitation-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/imitation-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/imitation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/imitation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Imitation learning aims to train models by mimicking human actions, which in theory, should enable the model to perform tasks similarly to how a human would. However, this approach faces several significant challenges:</p> <p>Optimal Action Inference:</p> <p>The assumption that the optimal action (a_t) can be inferred solely from the perceptual input (o_t) is often flawed. As highlighted in the text, this is particularly problematic when a car approaches an intersection. The camera input alone is insufficient to predict whether the car should turn left, right, or go straight. This scenario illustrates that additional context or commands ((c_t)) are necessary for accurate decision-making.</p> <p>Function Approximation Difficulties:</p> <p>The mapping from image to control command is not always a straightforward function. This complexity is exacerbated in real-world environments where multiple plausible actions can exist for a given situation. For instance, as mentioned in the paper, when a network reaches a fork, it may output two widely discrepant travel directions, one for each possible choice. This results in oscillations and instability in the dictated travel direction.</p> <p>The high-level overview in this Figure demonstrates the interaction between the controller and the environment:</p> <ul> <li><strong>Observation ((o_t))</strong>: The controller receives observations from the environment, which are the sensory inputs, such as images from cameras.</li> <li><strong>Command ((c_t))</strong>: The controller also receives high-level commands that provide context, such as “turn left” or “go straight.”</li> <li><strong>Action ((a_t))</strong>: Based on the observation and command, the controller produces an action that affects the environment.</li> <li><strong>Next Observation ((o_{t+1}))</strong>: The action results in a change in the environment, leading to the next observation.</li> </ul> <p>The figure underscores the necessity of combining both perceptual inputs and high-level commands to generate appropriate actions.</p> <h3 id="highlevelcommandloader">HighLevelCommandLoader</h3> <p>The <code class="language-plaintext highlighter-rouge">HighLevelCommandLoader</code> is designed to provide turn-by-turn instructions for a vehicle navigating through intersections. These instructions can either be predefined or selected randomly based on real-time intersection detection.</p> <p>Example Configuration</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 Right Right
77 1 166 Left Left
32 75 174 Right Straight
76 33 193 Straight Left
52 59 148 Left Right
69 51 136 Left Right
40 69 272 Straight Left
59 39 245 Right Straight
60 25 255 Straight Right
23 61 269 Left Straight
82 17 155 Right Left
18 83 140 Right Left
</code></pre></div></div> <p>Route Initialization:</p> <p>When initializing <code class="language-plaintext highlighter-rouge">HighLevelCommandLoader</code>, the route is provided:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc_loader</span> <span class="o">=</span> <span class="nc">HighLevelCommandLoader</span><span class="p">(</span><span class="n">vehicle</span><span class="p">,</span> <span class="n">world</span><span class="p">.</span><span class="nf">get_map</span><span class="p">(),</span> <span class="n">route</span><span class="p">)</span>
</code></pre></div></div> <p>Fetching High-Level Commands:</p> <p>In each simulation step, the next high-level command is fetched:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc</span> <span class="o">=</span> <span class="n">hlc_loader</span><span class="p">.</span><span class="nf">get_next_hlc</span><span class="p">()</span>
</code></pre></div></div> <p>Loading Next High-Level Command:</p> <p>If the vehicle is at an intersection and there is a predefined route, <code class="language-plaintext highlighter-rouge">load_next_hlc</code> loads the next command:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">route</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div> <p>If there is no predefined route, <code class="language-plaintext highlighter-rouge">get_random_hlc</code> randomly selects a command.</p> <h3 id="command-mapping">Command Mapping</h3> <p>Commands guide the vehicle’s behavior at intersections, ensuring it navigates according to the defined or random directions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">command</span><span class="p">):</span>
    <span class="n">commands</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">commands</span><span class="p">[</span><span class="n">command</span><span class="p">]</span>
</code></pre></div></div> <h3 id="integration-with-bert-model">Integration with BERT Model</h3> <ol> <li> <p><strong>Input Example:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="sh">"</span><span class="s">Make a left turn at the upcoming junction.</span><span class="sh">"</span>
</code></pre></div> </div> </li> <li> <p><strong>Tokenization:</strong></p> <ul> <li>The command is split into tokens and converted into a tensor of token IDs.</li> </ul> </li> <li> <p><strong>Prediction:</strong></p> <ul> <li>The token IDs are passed through the BERT model.</li> <li>The model outputs logits for each possible action class.</li> </ul> </li> </ol> <h3 id="modified-command-to-integer-mapping-with-bert">Modified Command-to-Integer Mapping with BERT</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">command</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tokenizer</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>

    <span class="c1"># Map predicted_class to corresponding actions
</span>    <span class="n">command_mapping</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># Left
</span>        <span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Right
</span>        <span class="mi">2</span><span class="p">:</span> <span class="mi">3</span>   <span class="c1"># Straight
</span>    <span class="p">}</span>

    <span class="k">return</span> <span class="n">command_mapping</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h3 id="example-flow">Example Flow</h3> <ol> <li><strong>Input:</strong> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="s2">"Make a left turn at the upcoming junction."</span>
</code></pre></div> </div> </li> <li> <p><strong>Processing:</strong></p> <ul> <li><strong>Tokenization:</strong> <ul> <li>Split the command into tokens.</li> <li>Convert tokens into tensor IDs.</li> </ul> </li> <li><strong>Prediction:</strong> <ul> <li>Pass tensor IDs through the BERT model.</li> <li>Obtain logits for action classes.</li> </ul> </li> </ul> </li> <li> <p><strong>Actions:</strong></p> <ul> <li><strong>Mapping:</strong> <ul> <li>Map predicted action class to predefined actions: <code class="language-plaintext highlighter-rouge">Left (1)</code>, <code class="language-plaintext highlighter-rouge">Right (2)</code>, <code class="language-plaintext highlighter-rouge">Straight (3)</code>.</li> </ul> </li> </ul> </li> </ol> <h3 id="data-mapping-example">Data Mapping Example</h3> <p>Input Data:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 Right Right
77 1 166 Left Left
32 75 174 Right Straight
76 33 193 Straight Left
52 59 148 Left Right
69 51 136 Left Right
40 69 272 Straight Left
59 39 245 Right Straight
60 25 255 Straight Right
23 61 269 Left Straight
82 17 155 Right Left
18 83 140 Right Left
</code></pre></div></div> <p>Mapped Commands:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
77 1 166 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
32 75 174 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
76 33 193 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
52 59 148 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
69 51 136 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
40 69 272 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
59 39 245 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
60 25 255 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
23 61 269 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
82 17 155 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
18 83 140 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
</code></pre></div></div> <p>Annotated Example:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 <span class="s2">"Make a right turn at the upcoming stop sign."</span> <span class="s2">"Merge onto the highway and take the second right exit."</span>
77 1 166 <span class="s2">"Make a left turn at the second stop sign."</span> <span class="s2">"Take the left turn onto Main Street at the upcoming intersection."</span>
32 75 174 <span class="s2">"Make a sharp right turn onto Maple Street."</span> <span class="s2">"Continue straight on the highway for the next 10 miles."</span>
76 33 193 <span class="s2">"Continue straight on the highway for the next 10 miles."</span> <span class="s2">"Make a left turn at the upcoming stop sign."</span>
52 59 148 <span class="s2">"Make a left turn at the upcoming roundabout."</span> <span class="s2">"Make a right turn at the stop sign ahead."</span>
69 51 136 <span class="s2">"Make a left turn at the upcoming stop sign."</span> <span class="s2">"Make a right turn onto Main Street after the gas station."</span>
40 69 272 <span class="s2">"Continue straight on the highway for the next 10 miles."</span> <span class="s2">"Make a left turn at the upcoming roundabout."</span>
59 39 245 <span class="s2">"Merge onto the highway and take the next right exit."</span> <span class="s2">"Continue straight on the highway for the next 10 miles."</span>
60 25 255 <span class="s2">"Continue driving straight on this road for two more miles."</span> <span class="s2">"Make a right turn onto Maple Street after the stop sign."</span>
23 61 269 <span class="s2">"Make a left turn at the stop sign ahead."</span> <span class="s2">"Continue straight on the highway for the next 5 miles."</span>
82 17 155 <span class="s2">"Make a right turn onto Main Street after passing the gas station on your left."</span> <span class="s2">"Make a left turn at the upcoming stop sign."</span>
18 83 140 <span class="s2">"Make a right turn onto Elm Street after the bridge."</span> <span class="s2">"Make a left turn at the stop sign ahead."</span>
</code></pre></div></div> <h3 id="next-steps">Next Steps</h3> <ol> <li><strong>Retrain the BERT Model</strong></li> <li><strong>Install the Simulator</strong></li> <li><strong>Integrate and Test with the Simulator</strong></li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week345 6/10-6/30</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-6-10-6-30/" rel="alternate" type="text/html" title="Coding week345 6/10-6/30"/><published>2024-06-30T00:00:00+00:00</published><updated>2024-06-30T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week345</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-6-10-6-30/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>In our recent meeting, we focused on enhancing our instruction generation process. I highlighted issues with data distribution, particularly the high similarity in GPT-generated data. To tackle this, we discussed strategies to balance our datasets, aiming to reduce redundancy and improve the diversity of the generated outputs. Sergio provided insights from previous projects, reviewing four key commands and proposing additional commands to enhance our current project’s functionality and efficiency. Additionally, we evaluated the metrics for our BERT model, agreeing that dividing the dataset into testing and training sets could yield acceptable results.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="data-generation">Data Generation</h3> <p>Currently, although our dataset is relatively balanced, the randomness of the data is not high, leading to a significant amount of duplicate data. To address this issue and improve the diversity of GPT-generated instructions, we’ve identified several solutions:</p> <p>Solution 1: Adjusting Parameters for Diversity</p> <p>By fine-tuning the <code class="language-plaintext highlighter-rouge">temperature</code> and <code class="language-plaintext highlighter-rouge">top_p</code> parameters, we can enhance the diversity of generated instructions. The temperature parameter controls the randomness of predictions by scaling the logits before applying softmax. A higher temperature results in more random outputs. The <code class="language-plaintext highlighter-rouge">top_p</code> parameter, also known as nucleus sampling, which ensures that the model considers only the <code class="language-plaintext highlighter-rouge">top p fraction</code> of cumulative probability mass, thus allowing for a more focused yet diverse set of outputs. By carefully balancing these parameters, we can generate a broader range of unique instructions.</p> <p>Solution 2: Increasing the Number of Samples Generated</p> <p>Generating a larger number of samples and then filtering out unique instructions can effectively increase diversity. This approach includes:</p> <ul> <li>Generating More Samples: Produce a higher volume of samples than needed, ensuring a wide variety of potential instructions.</li> <li>Dynamic Batch Size: Implement a dynamic batch size that adjusts according to the remaining number of samples to be generated. To avoid hard-coding the batch size, it is set to twice the number of remaining samples, but not exceeding 50. This flexibility ensures efficient use of resources while maintaining the target number of unique instructions.</li> <li>Collection De-duplication: Utilize collection auto-de-duplication to filter out duplicate instructions. After de-duplication, limit the collection to the desired number of unique instructions. This process ensures that the final set of instructions is both diverse and manageable.</li> </ul> <p>Solution 3: Adding Contextual Information</p> <p>Incorporating more contextual information into the prompts can help the model generate more diverse instructions. Providing detailed context allows the model to understand the nuances of the task better, leading to richer and more varied outputs. This could involve including specific scenarios, additional background information, or detailed task descriptions within the prompts. By doing so, we enable the model to generate instructions that are not only diverse but also more relevant and contextually appropriate.</p> <h3 id="iteration-method-example">Iteration Method Example</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/iter-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/iter-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/iter-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/iter.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In one iteration, generating unique instructions for the action ‘LaneFollow’ involved multiple steps.</p> <p>Similarly, generating instructions for actions like ‘Left’, ‘Right’, and ‘Straight’ required repeated attempts to reach the desired count of unique instructions, resulting in high redundancy and a longer processing time.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 25 / 25 unique instructions
                                          instruction        action
0   <span class="s2">"Enter the highway and LaneFollow the middle l...  [LaneFollow]
1   "</span>Continue straight on Main Street and LaneFoll...  <span class="o">[</span>LaneFollow]
2   <span class="s2">"Enter the highway and LaneFollow the traffic ...  [LaneFollow]
3   "</span>Enter the highway and LaneFollow the traffic ...  <span class="o">[</span>LaneFollow]
4   <span class="s2">"Once you enter the highway, activate LaneFoll...  [LaneFollow]
..                                                ...           ...
95  "</span>Continue driving straight on Main Street <span class="k">for</span> ...    <span class="o">[</span>Straight]
96    <span class="s2">"Continue straight on the highway for 5 miles."</span>    <span class="o">[</span>Straight]
97  <span class="s2">"Continue driving straight on Main Street for ...    [Straight]
98  "</span>Continue driving straight on this road <span class="k">for </span>an...    <span class="o">[</span>Straight]
99  <span class="s2">"Continue driving straight on this road for tw...    [Straight]

[100 rows x 2 columns]
Dataset generated and saved to 'dataset_1000.csv'
Generated 100 instructions in 221.16 seconds.
</span></code></pre></div></div> <h3 id="batch-method-example">Batch Method Example</h3> <p>By contrast, using a batch method improves efficiency and reduces redundancy. For example:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/batch-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/batch-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/batch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/batch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 25 / 25 unique instructions
                                          instruction        action
0   <span class="s2">"LaneFollow the vehicle in front of you as you...  [LaneFollow]
1   "</span>Continue LaneFollow on the highway <span class="k">for </span>the ne...  <span class="o">[</span>LaneFollow]
2   <span class="s2">"Once on the highway, LaneFollow and maintain ...  [LaneFollow]
3   "</span>Enter the highway and LaneFollow the middle l...  <span class="o">[</span>LaneFollow]
4   <span class="s2">"Stay in the right lane and LaneFollow the veh...  [LaneFollow]
..                                                ...           ...
95  "</span>Continue straight on the highway <span class="k">for </span>5 miles ...    <span class="o">[</span>Straight]
96  <span class="s2">"Continue straight on this road for the next 2...    [Straight]
97  "</span>Continue straight on the highway <span class="k">for </span>another ...    <span class="o">[</span>Straight]
98  <span class="s2">"Continue driving straight on this road for th...    [Straight]
99  "</span>Continue driving straight on the highway <span class="k">for</span> ...    <span class="o">[</span>Straight]

<span class="o">[</span>100 rows x 2 columns]
Dataset generated and saved to <span class="s1">'dataset_1000.csv'</span>
Generated 100 instructions <span class="k">in </span>158.48 seconds.
</code></pre></div></div> <p>The batch method resulted in fewer duplicate instructions and a significant improvement in processing time.</p> <ul> <li>Iteration Method: Generated 100 instructions with <strong>521</strong> duplicates in <strong>221.16</strong> seconds.</li> <li>Batch Method: Generated 100 instructions with <strong>122</strong> duplicates in <strong>158.48</strong> seconds.</li> </ul> <p>The batch method improved efficiency by <strong>28.34%</strong> and reduced duplicates by <strong>326.23%</strong> compared to the iteration method.</p> <h3 id="data-analysis">Data Analysis</h3> <p>In addition to optimizing the generation of instructions, I performed an analysis of the data distribution and created a word cloud to visualize the most frequently occurring terms. This analysis helped us understand the underlying patterns in the dataset and identify areas for improvement.</p> <p>Data Distribution Analysis</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/data_distribution_630-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/data_distribution_630-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/data_distribution_630-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/data_distribution_630.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>By examining the distribution of instructions across different actions, we identified four actions are balanced.</p> <p>Word Cloud</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/word_cloud_630-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/word_cloud_630-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/word_cloud_630-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/word_cloud_630.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The word cloud provided a visual representation of the most common terms in our dataset. Words like “continue,” “straight,” “left,” and “right” appeared frequently, indicating their prominence in the instructions. This visualization highlighted the need to diversify the vocabulary used in the generated instructions to enhance the overall richness and utility of the dataset.</p> <h3 id="scalable-of-datasets">Scalable of Datasets</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">: Generated </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">unique_instructions</span><span class="p">)</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">num_samples_per_action</span><span class="si">}</span><span class="s"> unique instructions</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 43 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 76 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 112 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 125 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 26 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 31 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 33 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 40 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 44 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 47 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 50 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 50 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 51 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 54 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 55 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 57 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 58 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 60 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 61 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 63 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 65 / 125 unique instructions
</code></pre></div></div> <p>The implication of our current approach is that approximately 98% of the instructions generated in each batch will be discarded. This high discard rate indicates an inherent limitation in the method, where repeated looping of a prompt leads to a significant number of duplicate instructions. This issue highlights the challenges associated with maintaining diversity and uniqueness in large-scale instruction generation.</p> <p>While we have successfully addressed issues related to small-scale data generation, balancing the dataset, and reducing data duplication, the challenge of data scaling remains unresolved. Scaling up our data generation processes without compromising diversity and quality is a complex problem that requires further exploration. If there is a demand for online large-scale data generation, we will need to develop and implement new strategies to handle these challenges. This may involve advanced techniques for dynamic prompt generation, more sophisticated filtering algorithms, and possibly leveraging real-time data augmentation methods to ensure a continuous stream of unique and varied instructions.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week2 6/03-6/09</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week2-6-03-6-09/" rel="alternate" type="text/html" title="Coding week2 6/03-6/09"/><published>2024-06-24T00:00:00+00:00</published><updated>2024-06-24T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week2</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week2-6-03-6-09/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>In this week’s meeting, we reviewed our project’s current status. We analyzed the high similarity observed in the outputs generated by GPT and discussed the issues of data distribution, which led to redundancy. To address these concerns, we brainstormed strategies to enhance the diversity and balance of our dataset. Additionally, we revisited four key commands from our previous project and explored how integrating more commands could boost both functionality and efficiency. We also deliberated on setting appropriate metrics for the BERT model by segmenting the dataset into training and testing sets.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="to-do-list">To-Do List</h3> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Generate scalable datasets that are intertwined with actions and commands with LLMs.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Perform quality analyses on the generated datasets.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Train the Bert model to classify instructions and obtain a model.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Move training and test notebooks in gsoc23 to a separate script. <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/5">issue</a></li> </ul> <h3 id="progress">Progress</h3> <p>This week, I developed a module designed to generate user-driving instructions using GPT. The code focuses on creating prompts based on predefined templates and user inputs, with an emphasis on improving the logic for prompt creation to enhance clarity and engagement. Additionally, the module includes features for validating user inputs and adjusting the output format accordingly. This advancement is beneficial for providing scalable instruction datasets in our project.</p> <p>The module also implements an action generation component, which formulates specific actions based on the instructions generated by GPT, such as “turn left,” “turn right,” “take exit,” “go straight,” “accelerate,” and “slow down.” Furthermore, I developed analytical tools within the prompt_analysis.py script to evaluate the effectiveness of the generated instructions, incorporating metrics to assess their relevance. Lastly, I implemented training using the BERT model to further enhance the module’s performance.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python train.py
1000 1000
Labels length: 1000
Input IDs length: 1000
Attention Mask length: 1000
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: <span class="o">[</span><span class="s1">'classifier.bias'</span>, <span class="s1">'classifier.weight'</span><span class="o">]</span>
You should probably TRAIN this model on a down-stream task to be able to use it <span class="k">for </span>predictions and inference.
<span class="o">{</span><span class="s1">'loss'</span>: 1.697, <span class="s1">'grad_norm'</span>: 19.306570053100586, <span class="s1">'learning_rate'</span>: 1.0000000000000002e-06, <span class="s1">'epoch'</span>: 0.09<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.617, <span class="s1">'grad_norm'</span>: 13.708064079284668, <span class="s1">'learning_rate'</span>: 2.0000000000000003e-06, <span class="s1">'epoch'</span>: 0.18<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.4665, <span class="s1">'grad_norm'</span>: 9.595329284667969, <span class="s1">'learning_rate'</span>: 3e-06, <span class="s1">'epoch'</span>: 0.27<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.2224, <span class="s1">'grad_norm'</span>: 12.889700889587402, <span class="s1">'learning_rate'</span>: 4.000000000000001e-06, <span class="s1">'epoch'</span>: 0.35<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.0262, <span class="s1">'grad_norm'</span>: 10.967733383178711, <span class="s1">'learning_rate'</span>: 5e-06, <span class="s1">'epoch'</span>: 0.44<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.7739, <span class="s1">'grad_norm'</span>: 13.827258110046387, <span class="s1">'learning_rate'</span>: 6e-06, <span class="s1">'epoch'</span>: 0.53<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.7852, <span class="s1">'grad_norm'</span>: 5.5881853103637695, <span class="s1">'learning_rate'</span>: 7.000000000000001e-06, <span class="s1">'epoch'</span>: 0.62<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.6525, <span class="s1">'grad_norm'</span>: 8.820500373840332, <span class="s1">'learning_rate'</span>: 8.000000000000001e-06, <span class="s1">'epoch'</span>: 0.71<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3866, <span class="s1">'grad_norm'</span>: 4.9470295906066895, <span class="s1">'learning_rate'</span>: 9e-06, <span class="s1">'epoch'</span>: 0.8<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3203, <span class="s1">'grad_norm'</span>: 3.308020830154419, <span class="s1">'learning_rate'</span>: 1e-05, <span class="s1">'epoch'</span>: 0.88<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3612, <span class="s1">'grad_norm'</span>: 9.319038391113281, <span class="s1">'learning_rate'</span>: 1.1000000000000001e-05, <span class="s1">'epoch'</span>: 0.97<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3051, <span class="s1">'grad_norm'</span>: 8.626148223876953, <span class="s1">'learning_rate'</span>: 1.2e-05, <span class="s1">'epoch'</span>: 1.06<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3143, <span class="s1">'grad_norm'</span>: 4.779806613922119, <span class="s1">'learning_rate'</span>: 1.3000000000000001e-05, <span class="s1">'epoch'</span>: 1.15<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2742, <span class="s1">'grad_norm'</span>: 8.452868461608887, <span class="s1">'learning_rate'</span>: 1.4000000000000001e-05, <span class="s1">'epoch'</span>: 1.24<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3953, <span class="s1">'grad_norm'</span>: 3.7451024055480957, <span class="s1">'learning_rate'</span>: 1.5e-05, <span class="s1">'epoch'</span>: 1.33<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2989, <span class="s1">'grad_norm'</span>: 0.8715028762817383, <span class="s1">'learning_rate'</span>: 1.6000000000000003e-05, <span class="s1">'epoch'</span>: 1.42<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3149, <span class="s1">'grad_norm'</span>: 9.316072463989258, <span class="s1">'learning_rate'</span>: 1.7000000000000003e-05, <span class="s1">'epoch'</span>: 1.5<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1399, <span class="s1">'grad_norm'</span>: 8.054197311401367, <span class="s1">'learning_rate'</span>: 1.8e-05, <span class="s1">'epoch'</span>: 1.59<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.246, <span class="s1">'grad_norm'</span>: 7.560857772827148, <span class="s1">'learning_rate'</span>: 1.9e-05, <span class="s1">'epoch'</span>: 1.68<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.151, <span class="s1">'grad_norm'</span>: 0.3591634929180145, <span class="s1">'learning_rate'</span>: 2e-05, <span class="s1">'epoch'</span>: 1.77<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1007, <span class="s1">'grad_norm'</span>: 7.88149881362915, <span class="s1">'learning_rate'</span>: 2.1e-05, <span class="s1">'epoch'</span>: 1.86<span class="o">}</span>
 63%|█████████████████████████████████████████████████████████████████████████████████▏                                              | 215/33 64%|████████████████████████████████████████████████████████████████▉                                     | 216/339 <span class="o">[</span>00:55&lt;00:31,  3.93it/s]<span class="o">{</span><span class="s1">'loss'</span>: 0.1223, <span class="s1">'grad_norm'</span>: 1.4635449647903442, <span class="s1">'learning_rate'</span>: 2.2000000000000003e-05, <span class="s1">'epoch'</span>: 1.95<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1039, <span class="s1">'grad_norm'</span>: 17.848655700683594, <span class="s1">'learning_rate'</span>: 2.3000000000000003e-05, <span class="s1">'epoch'</span>: 2.04<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2297, <span class="s1">'grad_norm'</span>: 0.22711549699306488, <span class="s1">'learning_rate'</span>: 2.4e-05, <span class="s1">'epoch'</span>: 2.12<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2394, <span class="s1">'grad_norm'</span>: 0.3263954222202301, <span class="s1">'learning_rate'</span>: 2.5e-05, <span class="s1">'epoch'</span>: 2.21<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2566, <span class="s1">'grad_norm'</span>: 0.4583888351917267, <span class="s1">'learning_rate'</span>: 2.6000000000000002e-05, <span class="s1">'epoch'</span>: 2.3<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1733, <span class="s1">'grad_norm'</span>: 0.12949731945991516, <span class="s1">'learning_rate'</span>: 2.7000000000000002e-05, <span class="s1">'epoch'</span>: 2.39<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1403, <span class="s1">'grad_norm'</span>: 0.12070054560899734, <span class="s1">'learning_rate'</span>: 2.8000000000000003e-05, <span class="s1">'epoch'</span>: 2.48<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2578, <span class="s1">'grad_norm'</span>: 0.15354938805103302, <span class="s1">'learning_rate'</span>: 2.9e-05, <span class="s1">'epoch'</span>: 2.57<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1055, <span class="s1">'grad_norm'</span>: 0.30441755056381226, <span class="s1">'learning_rate'</span>: 3e-05, <span class="s1">'epoch'</span>: 2.65<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2079, <span class="s1">'grad_norm'</span>: 16.82185935974121, <span class="s1">'learning_rate'</span>: 3.1e-05, <span class="s1">'epoch'</span>: 2.74<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2025, <span class="s1">'grad_norm'</span>: 4.622957229614258, <span class="s1">'learning_rate'</span>: 3.2000000000000005e-05, <span class="s1">'epoch'</span>: 2.83<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1915, <span class="s1">'grad_norm'</span>: 18.763633728027344, <span class="s1">'learning_rate'</span>: 3.3e-05, <span class="s1">'epoch'</span>: 2.92<span class="o">}</span>
<span class="o">{</span><span class="s1">'train_runtime'</span>: 84.7519, <span class="s1">'train_samples_per_second'</span>: 31.858, <span class="s1">'train_steps_per_second'</span>: 4.0, <span class="s1">'train_loss'</span>: 0.45582248397984687, <span class="s1">'epoch'</span>: 3.0<span class="o">}</span>
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 339/339 <span class="o">[</span>01:24&lt;00:00,  4.00it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 <span class="o">[</span>00:00&lt;00:00, 11.49it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 <span class="o">[</span>00:00&lt;00:00, 11.14it/s]
              precision    recall  f1-score   support

           0       0.99      0.96      0.97        89
           1       0.71      0.91      0.80        11

    accuracy                           0.95       100
   macro avg       0.85      0.93      0.89       100
weighted avg       0.96      0.95      0.95       100
</code></pre></div></div> <h3 id="challenges">Challenges</h3> <p>During the data generation process, I encountered a significant issue with data imbalance. By using GPT to generate 1000 data points, I discovered that the distribution of the data was uneven, as illustrated below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/wordcloud-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/wordcloud-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/wordcloud-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/wordcloud.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/datasets-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/datasets-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/datasets-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/datasets.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/distribution-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/distribution-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>From the database analysis, we observed an increased presence of data duplicates, such as the instruction “Approaching the roundabout.” Consequently, the model’s interpretation of this instruction has predominantly skewed towards “take exit.” This repetition is also evident in the word cloud, where several words appear repeatedly. This issue results in an unbalanced distribution of data, which affects the model’s performance and accuracy in understanding diverse driving instructions.</p> <p>Although the BERT model achieved satisfactory accuracy, the skewed data distribution poses challenges for real-world application. The model’s performance might not generalize well to new, unseen data if it does not reflect a balanced representation of all possible scenarios. This imbalance could lead to biased predictions and reduced effectiveness in practical use cases. Addressing this challenge will be crucial to ensure the robustness and reliability of the instructional generation system. Potential solutions include augmenting the dataset to ensure balance or applying bias correction methods during the model training phase.</p> <h3 id="future-tasks">Future Tasks</h3> <ul> <li>Continue refining the data balancing strategies to further improve the diversity of generated outputs.</li> <li>Complete the integration and testing of additional commands from previous projects.</li> <li>Optimize the model training process and evaluate the effectiveness of the dataset division.</li> </ul>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry></feed>