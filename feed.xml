<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml" rel="self" type="application/atom+xml"/><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-09T13:55:40+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/feed.xml</id><title type="html">Zebin Huang | JdeRobot x GSoC2024</title><subtitle>Zebin Huang | JdeRobot x GSoC2024 </subtitle><entry><title type="html">Coding week10&amp;amp;11 7/29-8/11</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-29-8-11/" rel="alternate" type="text/html" title="Coding week10&amp;amp;11 7/29-8/11"/><published>2024-08-21T00:00:00+00:00</published><updated>2024-08-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1011</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-29-8-11/"><![CDATA[<p>Over the past two weeks, our focus has been on addressing several tasks for the ongoing development of our project. Here is a summary of the key action items, progress, and additional insights that have emerged during this period:</p> <ol> <li><strong>Mid-Term Evaluation</strong>: <ul> <li>We have been meticulously preparing for the mid-term evaluation, including our progress, documentation, and demos. The feedback from this evaluation will guide the next steps of our development.</li> </ul> </li> <li><strong>Fixing Video Issues in the Blog</strong>: <ul> <li>To resolve this, the video will be uploaded to a trusted platform like YouTube or Google Drive, ensuring that it is easily accessible to all viewers.</li> </ul> </li> <li><strong>Mid-Term Demo Video</strong>: <ul> <li>A critical component of our mid-term deliverables is the demonstration video showcasing the current capabilities of our model within the simulation environment. This video will highlight how the model processes and classifies different driving scenarios.</li> </ul> </li> <li><strong>Improving Dataset Evaluation</strong>: <ul> <li>We are actively exploring ways to enhance the synthetic dataset generation process, focusing on creating more diverse datasets without directly embedding commands into the instructions. The goal is to ensure that the generated data is both rich in context and relevant to our classification tasks. We are using resources such as: <ul> <li><a href="https://huggingface.co/learn/cookbook/rag_evaluation">RAG Evaluation Cookbook</a></li> <li><a href="https://huggingface.co/learn/cookbook/llm_judge">LLM Judge Evaluation Cookbook</a></li> </ul> </li> <li>These resources provide some inspiration for improving the evaluation process.</li> </ul> </li> <li><strong>Future Works</strong>: <ul> <li>As we look ahead, we are conducting a literature review to identify potential research avenues that can further enhance our project. The LMDrive repository and similar projects offer valuable insights into how we can refine our approach and explore new research ideas. We are particularly interested in extending our work to incorporate more advanced LLM techniques.</li> <li>Additionally, to show the project in action, all scripts are integrated into a web app through the Streamlit platform.</li> </ul> </li> </ol> <h3 id="streamlit-development">Streamlit Development</h3> <p>The recent development efforts have been centred on implementing a Streamlit-based app for our project. This app can make the tool more accessible and user-friendly.</p> <p><strong>Design and Architecture</strong></p> <ul> <li>The Streamlit app has been designed with a modular architecture, allowing for easy scaling and adaptation. I have already encapsulated the scripts independently, which now allows for quick splitting and building of the app through different modular pages.</li> <li>The main pages include: <ul> <li><strong>Data Generation</strong>: Users can generate datasets required for training models. This page provides the tools necessary to create diverse and robust datasets.</li> <li><strong>Data Analysis</strong>: This section allows users to analyze the generated or uploaded data. Visualization tools are integrated to help users understand the data distribution and key metrics at a glance.</li> <li><strong>Model Training</strong>: In this section, users can initiate model training sessions. The interface includes options for viewing logs and evaluating interim results. It also allows for customization of training parameters to optimize performance.</li> <li><strong>Check Logs</strong>: Users can review detailed logs from the data generation, analysis, and model training processes. This helps in debugging and ensures transparency in the operations performed by the app.</li> <li><strong>Model Testing</strong>: This page allows users to test the BERT model online with single instructions or files.</li> </ul> </li> </ul> <p><strong>Data Import/Export Interface</strong></p> <ul> <li>For online deployment, we should also implement a data import/export mechanism. Unlike the local environment, the online version requires handling real-time data flow effectively. We implemented a streamlined interface that allows users to upload data files easily and download results in various formats.</li> <li>Below is a snapshot of the code handling data import/export:</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_pdf_report</span><span class="p">(</span><span class="n">train_fig</span><span class="p">,</span> <span class="n">eval_fig</span><span class="p">,</span> <span class="n">train_log</span><span class="p">,</span> <span class="n">eval_log</span><span class="p">,</span> <span class="n">cls_report</span><span class="p">,</span> <span class="n">folder_path</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Convert logs and figures into an HTML and generate a PDF report.</span><span class="sh">"""</span>

    <span class="c1"># Convert train figure to base64
</span>    <span class="n">buffer1</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">()</span>
    <span class="n">train_fig</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">buffer1</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">buffer1</span><span class="p">.</span><span class="nf">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">train_base64</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">buffer1</span><span class="p">.</span><span class="nf">read</span><span class="p">()).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">train_img_html</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="sh">'</span><span class="s">&lt;img src=</span><span class="sh">"</span><span class="s">data:image/png;base64,</span><span class="si">{</span><span class="n">train_base64</span><span class="si">}</span><span class="sh">"</span><span class="s"> </span><span class="sh">'</span>
        <span class="sh">'</span><span class="s">style=</span><span class="sh">"</span><span class="s">width: 80%; max-width: 800px;</span><span class="sh">"</span><span class="s">/&gt;</span><span class="sh">'</span>
    <span class="p">)</span>

    <span class="c1"># Convert eval figure to base64
</span>    <span class="n">buffer2</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nc">BytesIO</span><span class="p">()</span>
    <span class="n">eval_fig</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="n">buffer2</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">png</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">buffer2</span><span class="p">.</span><span class="nf">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">eval_base64</span> <span class="o">=</span> <span class="n">base64</span><span class="p">.</span><span class="nf">b64encode</span><span class="p">(</span><span class="n">buffer2</span><span class="p">.</span><span class="nf">read</span><span class="p">()).</span><span class="nf">decode</span><span class="p">(</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">eval_img_html</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="sh">'</span><span class="s">&lt;img src=</span><span class="sh">"</span><span class="s">data:image/png;base64,</span><span class="si">{</span><span class="n">eval_base64</span><span class="si">}</span><span class="sh">"</span><span class="s"> </span><span class="sh">'</span>
        <span class="sh">'</span><span class="s">style=</span><span class="sh">"</span><span class="s">width: 80%; max-width: 800px;</span><span class="sh">"</span><span class="s">/&gt;</span><span class="sh">'</span>
    <span class="p">)</span>

    <span class="c1"># Generate markdown for logs
</span>    <span class="n">train_log_md</span><span class="p">,</span> <span class="n">eval_log_md</span><span class="p">,</span> <span class="n">cls_report_md</span> <span class="o">=</span> <span class="nf">generate_markdown</span><span class="p">(</span>
        <span class="n">train_log</span><span class="p">,</span> <span class="n">eval_log</span><span class="p">,</span> <span class="n">cls_report</span>
    <span class="p">)</span>
    <span class="n">train_html</span><span class="p">,</span> <span class="n">eval_html</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">train_log_md</span><span class="p">),</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">eval_log_md</span><span class="p">),</span>
        <span class="nf">markdown</span><span class="p">(</span><span class="n">cls_report_md</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Create HTML content
</span>    <span class="n">html_content</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;Markdown&lt;/title&gt;
        &lt;style&gt;
            body 
            img 
            .page-break 
        &lt;/style&gt;
    &lt;/head&gt;
    &lt;body&gt;
        </span><span class="si">{</span><span class="n">train_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">train_img_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">eval_html</span><span class="si">}</span><span class="s">
        </span><span class="si">{</span><span class="n">eval_img_html</span><span class="si">}</span><span class="s">

    &lt;/body&gt;
    &lt;/html&gt;
    </span><span class="sh">"""</span>

    <span class="c1"># Convert HTML to PDF
</span>    <span class="n">pdf_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">folder_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">logs_report.pdf</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">convert_html_to_pdf</span><span class="p">(</span><span class="n">html_content</span><span class="p">,</span> <span class="n">pdf_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pdf_path</span>
</code></pre></div></div> <p><strong>Challenges in Model Storage</strong></p> <ul> <li>A significant technical challenge was how to manage the storage and export of models trained online. Given the constraints of bandwidth and storage, exporting large models like BERT is not feasible within our current setup. Therefore, we opted for TinyBERT, a more compact model that has shown excellent performance in our tests, achieving nearly 100% accuracy in the scenarios we’ve evaluated.</li> <li>Referring to this article <a href="https://blog.streamlit.io/common-app-problems-resource-limits/">here</a>, Streamlit currently has resource limitations, which prevent us from freely training and exporting pre-trained models. This feature in our app is not yet fully supported. We are considering using Github’s Large File Storage, but this solution has not been fully tested yet.</li> </ul> <h3 id="llm-evaluation"><strong>LLM Evaluation</strong></h3> <p>In addition to implementing the Streamlit app, we have been exploring various cookbooks from Hugging Face suggested by mentors to refine our approach. However, this exploration has also revealed several challenges:</p> <ol> <li><strong>Sample Size Insufficiency</strong>: The current dataset might not be large enough to fully train more complex models. We are considering various data augmentation strategies to increase the dataset’s size and diversity.</li> <li><strong>Evaluation of Human Input</strong>: The evaluation methods we currently use are heavily reliant on human judgment. To address this, we are exploring automated evaluation techniques that can provide consistent and scalable assessments.</li> <li><strong>Lack of Trials</strong>: The limited availability of real-world data and trials has been a bottleneck. To overcome this, some self-supervised methods should be explored.</li> </ol> <h3 id="model-inference">Model Inference</h3> <p>We conducted a series of comparative experiments to determine whether the model inference stage significantly impacts decision-making within the simulation. Our findings indicate that the model’s decisions remain consistent, even under varied conditions.</p> <p>Interestingly, we discovered that some collision issues initially thought to be caused by the model inference stage, were actually rooted in problems with the previous model version. To provide more insight, we have attached both error videos and examples of correct simulations.</p> <iframe width="700" height="500" src="https://www.youtube.com/embed/1Fg6R5mZLHE" title="Control with bert" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <iframe width="700" height="500" src="https://www.youtube.com/embed/urk-g_el_gg" title="Crash without bert" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="next-steps">Next Steps</h3> <p>I have prepared a mid-term summary video, which will be submitted for feedback. This video summarizes the current status of the project. Based on the feedback received, we will make the necessary adjustments to ensure that the project continues to meet its objectives and align with the broader goals of the GSoC initiative.</p> <p>Moving forward, we will delve deeper into the literature, exploring new research directions that could lead to improvements in the model’s performance and its integration within the CARLA simulation environment.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Over the past two weeks, our focus has been on addressing several tasks for the ongoing development of our project. Here is a summary of the key action items, progress, and additional insights that have emerged during this period:]]></summary></entry><entry><title type="html">Coding week8 7/15-7/21</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-15-7-21/" rel="alternate" type="text/html" title="Coding week8 7/15-7/21"/><published>2024-07-21T00:00:00+00:00</published><updated>2024-07-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week8</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-15-7-21/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During this week’s meeting, the team discussed several key updates and future plans. Sergio and Apoorv reminded me to provide weekly updates on the project blog to track progress and evaluation. I recapped the data generation process, highlighting issues with high duplication and the implementation of strategies like dynamic batch size and the iterative method, which improved speed by 28%. However, scalability issues were noted. I also discussed the high-level command design for the demo, simulator installation challenges, and the retraining of the BERT model, which achieved 100% accuracy with 300 samples. Environmental issues were addressed, but data collection and iteration interruptions remained problematic. In the open floor discussion, the team explored future directions, such as using world models or simulators to improve data efficiency and considering external datasets. Sergio outlined the next steps, including integrating the new BERT model into the pipeline, publishing code and results, and potentially developing a Streamlit demo app.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="setting-up-carla-with-a-graphical-interface">Setting Up CARLA with a Graphical Interface</h3> <p>Because we have been developing CARLA within Docker, setting up a graphical interface is essential for better visualization and simulation. This week, I attempted to establish this environment, initially assuming it would be relatively straightforward. However, this task proved to be quite time-consuming.</p> <p>CARLA Basic Hardware Requirements</p> <p>Before diving into the setup process, it is crucial to understand the basic hardware requirements for running CARLA smoothly:</p> <ul> <li>CPU: Intel i5-8600k or higher</li> <li>GPU: NVIDIA GeForce GTX 1080 or equivalent</li> <li>RAM: 16 GB</li> <li>Storage: SSD with at least 50 GB of free space</li> <li>Operating System: Ubuntu 18.04/20.04 or Windows 10/Server 2019</li> </ul> <p>Initially, I planned to set up CARLA on headless servers. Here’s a summary of the challenges faced:</p> <p><strong>Windows Server 2019</strong>: The setup on a Windows Server 2019 system was expected to be straightforward. However, this older system caused numerous issues, leading to persistent errors as shown in the image below. These errors were likely due to compatibility issues with the older Windows version.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/win_error-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/win_error-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/win_error-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/win_error.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Ubuntu Server</strong>: Another attempt was made on an Ubuntu server. Unfortunately, due to being on a university’s internal network, port restrictions prevented the use of VNC for desktop access. This limitation made it challenging to run CARLA with a graphical interface.</p> <p>Given these challenges, the only viable option was to run CARLA on a physical desktop machine. This approach allowed me to bypass the issues encountered with headless servers and internal network restrictions. Finally, here is a video of the trained model running on CARLA:</p> <iframe width="700" height="500" src="https://www.youtube.com/embed/1FJVz80yBFQ" title="Carla_deployment_test" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="model-training-and-optimization">Model Training and Optimization</h3> <p>Over the past week, several improvements have been made to our model in performance and flexibility. These updates include:</p> <ol> <li> <p><strong>Training with a New Dataset</strong>: The model was retrained using a new and more comprehensive dataset, which led to an improvement in prediction accuracy. The retraining process resulted in the model achieving nearly 100% accuracy, demonstrating the effectiveness of the new data.</p> </li> <li> <p><strong>Model Size Optimization</strong>: To optimize performance and resource usage, different versions of the model were tested, including <code class="language-plaintext highlighter-rouge">bert_model</code>, <code class="language-plaintext highlighter-rouge">distilbert_model</code>, and <code class="language-plaintext highlighter-rouge">tinybert_model</code>. Each version showed significant differences in terms of speed and memory consumption. Despite these differences, all versions maintained a high level of accuracy. This experimentation highlights the potential for deploying smaller, more efficient models without compromising on performance.</p> </li> <li> <p><strong>Code Refactoring</strong>: The codebase underwent extensive refactoring to improve maintainability. The model-related code was updated to fully accept parameters. Additionally, new testing interfaces were implemented, which enable both single instruction inputs and file-based inputs. These interfaces facilitate more testing and validation of the model under various scenarios.</p> </li> </ol> <p>These improvements enhance the model’s robustness, efficiency, and adaptability.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">-rw-r--r--</span>  1 zebin  staff   418M Jul 24 06:59 bert_model.pt
<span class="nt">-rw-r--r--</span>  1 zebin  staff   255M Jul 24 06:38 distilbert_model.pt
<span class="nt">-rw-r--r--</span>  1 zebin  staff    55M Jul 24 07:14 tinybert_model.pt
</code></pre></div></div> <h2 id="model-integration">Model integration</h2> <p>To independently verify that the LLM language module is functioning correctly, a <code class="language-plaintext highlighter-rouge">config_translator</code> was created. This tool uses the GPT interface to generate instructions based on some predefined actions found in the <code class="language-plaintext highlighter-rouge">test_suites</code>. Below are the generation results for <code class="language-plaintext highlighter-rouge">Town02_All.txt</code>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/test_suite-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/test_suite-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/test_suite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/test_suite.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Two online testing methods for the model were established. One method involves testing through a single instruction, while the other involves testing through a configuration data file. Below are the model prediction results for <code class="language-plaintext highlighter-rouge">Town02_All.txt</code> (the last two actions on the right are model predictions). As you can see, the results are consistent.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/pred_test_suite-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/pred_test_suite-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/pred_test_suite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/pred_test_suite.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="code-refactoring">Code Refactoring</h3> <p>Recent efforts in code refactoring have focused on improving robustness, flexibility, and maintainability. Here are the key improvements:</p> <ol> <li>Exception Handling: We have implemented exception handling across the codebase to manage potential errors more effectively. This includes: <ul> <li>Invalid Configuration Formats: Ensuring that the system gracefully handles incorrect or malformed configuration files.</li> <li>Invalid Actions: Adding checks to handle scenarios where actions specified are not recognized or are outside the expected range.</li> <li>Non-existent Directories: Implementing safeguards to manage cases where required directories are missing.</li> </ul> </li> <li> <p>Parameterization: All scripts have been fully parameterized, enhancing their flexibility and ease of use. Parameterization allows users to adjust script behavior without modifying the underlying code, facilitating.</p> </li> <li>Configuration File and Utilities: To further improve code maintainability, we have introduced an independent configuration file and a set of utility functions: <ul> <li>Configuration File: Centralizes all configuration settings, making it easier to manage and update system-wide settings in one place. This separation of configuration from code simplifies adjustments and reduces the risk of errors.</li> <li>Utility Functions (<code class="language-plaintext highlighter-rouge">utils</code>): A dedicated set of utility functions has been created to handle common tasks and operations. Common operations are abstracted into these utility functions, which can be easily called from different parts of the project.</li> </ul> </li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week9 7/22-7/28</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-22-7-28/" rel="alternate" type="text/html" title="Coding week9 7/22-7/28"/><published>2024-07-21T00:00:00+00:00</published><updated>2024-07-21T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week9</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week8-7-22-7-28/"><![CDATA[<p>This blog post serves as a comprehensive update on our progress, challenges, and future plans, providing a clear picture of where the project stands and where it is headed. We look forward to the next phase of development.</p> <h3 id="introduction">Introduction</h3> <p>This project aims to advance the intersection of Large Language Models (LLMs) and autonomous driving simulation. To better understand the architecture of this project, let’s take a closer look at the project’s overall framework. This framework illustrates the workflow, starting with the generation of synthetic data through LLMs, followed by training a BERT model with this data. Finally, the trained model is integrated into the CARLA simulator.</p> <p>The project is divided into two distinct yet interconnected parts:</p> <ol> <li><strong>Data Generation and BERT Model Training</strong>: The initial phase involves leveraging LLMs to generate diverse scalable datasets. These datasets are then used to train a BERT series model for specific classification tasks related to autonomous driving scenarios.</li> <li><strong>CARLA Simulation</strong>: The second phase focuses on integrating the trained BERT model into the CARLA simulator. This integration is designed to enhance the simulation’s ability to classify and respond to various human instructions, thereby improving the overall decision-making process.</li> </ol> <h3 id="video-demo">Video Demo</h3> <p>As part of the mid-term deliverable, a video demonstrating the project’s current capabilities has been prepared. This video showcases how the BERT model, trained with LLM-generated data, functions within the CARLA simulator.</p> <p><a href="https://gsoc24-zebinhuang.streamlit.app/"><img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg" alt="Streamlit App"/></a></p> <iframe width="700" height="500" src="https://www.youtube.com/embed/bigQi9wnrdY" title="GSoC24 Midterm Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <h3 id="challenges">Challenges</h3> <p>Throughout the development process, several significant challenges were encountered, particularly in the following areas:</p> <ol> <li><strong>Performance and Reliability of Data Generation</strong>: One of the core challenges was ensuring that the data generated by the LLMs was both relevant and diverse enough to effectively train the BERT model. The quality of this synthetic data directly impacts the model’s performance, making it crucial to address issues related to data generation reliability and efficiency.</li> <li><strong>Integration of BERT with CARLA</strong>: While the integration of the BERT model into the CARLA simulator marks a significant step forward, it was noted that the integration was not as seamless as desired. The classifier model, trained using LLM-generated data, currently operates somewhat independently of the broader autonomous driving system. As a result, the full potential of the LLM in enhancing the CARLA simulation has not yet been fully realized. For information on how to integrate models into CARLA, check out this <a href="https://github.com/TheRoboticsClub/gsoc2024-ZebinHuang/pull/3">PR</a>.</li> </ol> <h3 id="limitations-and-future-works">Limitations and Future Works</h3> <p>Despite the progress made, the project has several limitations that need to be addressed in future iterations:</p> <ol> <li><strong>Limited Integration of LLM</strong>: The current integration between the LLM-generated data and the CARLA simulator is not fully optimized. The BERT model functions as a standalone classifier rather than being deeply embedded within the autonomous driving system. This limits the overall impact of the LLM on the simulation’s performance. This would involve developing methods to enable real-time scenario understanding and decision-making within the simulator, leveraging the strengths of both LLMs and autonomous driving technologies.</li> <li><strong>Quality Evaluation of Datasets</strong>: The project has primarily focused on the generation of synthetic data. However, the evaluation of this data’s quality remains an area that requires further exploration. Future work will need to develop self-supervised evaluation methods that can assess data quality without human intervention. These techniques would allow for automated, scalable assessments of synthetic data, improving the overall reliability and effectiveness of the training datasets.</li> <li><strong>Bridging the Sim2Real Gap</strong>: Another key area of research could involve bridging the gap between simulated data and real-world driving data. This would involve refining the synthetic data generation process to more closely mirror real-world conditions, thus making the models trained on this data more applicable to real-world autonomous driving scenarios.</li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[This blog post serves as a comprehensive update on our progress, challenges, and future plans, providing a clear picture of where the project stands and where it is headed. We look forward to the next phase of development.]]></summary></entry><entry><title type="html">Coding week7 7/08-7/14</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week7-7-08-7-14/" rel="alternate" type="text/html" title="Coding week7 7/08-7/14"/><published>2024-07-14T00:00:00+00:00</published><updated>2024-07-14T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week7</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week7-7-08-7-14/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During the July 10 meeting, we focused on refining our dataset and integrating our models into the overall framework. We discussed the use of iterative generation techniques to remove duplicated lines from our datasets, aiming to establish a robust baseline for our project. We also explored the implementation of high-level commands with text inputs for the model.</p> <p>Two key questions were raised during the meeting:</p> <ul> <li>Route Selection: If there is no predefined route, the function <code class="language-plaintext highlighter-rouge">get_random_hlc</code> will randomly select a command. This method needs further clarification to ensure it aligns with our overall approach.</li> <li>Instruction Classification: There was a discussion on the necessity of predefined data for classification purposes. Despite having the ground truth, the reason for classifying predefined data needs further elaboration to ensure it enhances the model’s performance effectively. These discussions and clarifications are crucial as we integrate the model into the framework, moving towards our project’s first baseline.</li> </ul> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="data-generation-performance-optimization">Data Generation Performance Optimization</h3> <p>Recently, the focus has been on optimizing the performance of data generation. In previous work, it was noticeable that calling the API consumed a significant amount of time. Here is a potential analysis of the reasons for the slowness, which may involve two situations:</p> <ol> <li>The number of parallel requests is too small, resulting in request limitations.</li> <li>Each call requires a long return time.</li> </ol> <h3 id="api-rate-limits">API Rate Limits</h3> <p>I checked the <a href="https://platform.openai.com/docs/guides/rate-limits">GPT documentation</a> and found the following notes on rate limits.</p> <p><em>Rate limits</em></p> <p><em>Rate limits are restrictions that our API imposes on the number of times a user or client can access our services within a specified period of time.</em></p> <p><em>How do these rate limits work?</em></p> <p><em>Rate limits are measured in five ways: <strong>RPM</strong> (requests per minute), <strong>RPD</strong> (requests per day), <strong>TPM</strong> (tokens per minute), <strong>TPD</strong> (tokens per day), and <strong>IPM</strong> (images per minute). Rate limits can be hit across any of the options depending on what occurs first. For example, you might send 20 requests with only 100 tokens to the ChatCompletions endpoint and that would fill your limit (if your RPM was 20), even if you did not send 150k tokens (if your TPM limit was 150k) within those 20 requests.</em></p> <p>OpenAI calculates different rates based on different prepayment levels. Currently, my account is at Tier 2. As observed, even within Tier 2, GPT-3.5-turbo is faster than GPT-4. This means there are more parallel requests available. Therefore, the performance bottleneck should mainly be in point 2: <strong>each call requires a long return time</strong>. I speculate that the performance bottleneck is likely due to the time taken for each request’s model inference and the network latency.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/rate_limit-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/rate_limit-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/rate_limit-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/rate_limit.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="how-can-we-reduce-the-number-of-calls">How can we reduce the number of calls?</h3> <p>In the original code, instructions generation was done one by one, meaning each time a command was generated, an API call was made. Even with the Batch method, the implementation of this batch method does not reduce <strong>the number of API calls</strong>.</p> <p>This method becomes very slow when a large number of commands need to be generated because each API call incurs network latency and processing time. Additionally, if the generated commands are duplicated, they need to be regenerated, further increasing the time consumption.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/batch-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/batch-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/batch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/batch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To improve the speed of command generation, we have adopted the following two main optimization methods:</p> <ol> <li>Batch Generation with One-time Request: One-time request can reduce the number of API calls, thereby reducing the overhead of network latency and processing time for each call. <ul> <li>Implementation: By using the <code class="language-plaintext highlighter-rouge">n</code> parameter of the <code class="language-plaintext highlighter-rouge">openai.chat.completions.create</code> method, multiple commands can be generated at once. For example, a single API call can generate 5 commands instead of making 5 separate calls to generate 1 command each time.</li> <li>Prompt: Currently, the prompt can only generate one command at a time. Modifying it to generate <code class="language-plaintext highlighter-rouge">batch_size</code> commands at once can significantly reduce the number of API calls.</li> </ul> </li> </ol> <p>Original prompt:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_instruction_prompt</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate a prompt for the OpenAI API to create a driving instruction for a given action.
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    Generate a short driving instruction that includes the action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">. Here are three examples:
    1. </span><span class="sh">"</span><span class="s">Turn right at the next intersection.</span><span class="sh">"</span><span class="s">
    2. </span><span class="sh">"</span><span class="s">Go straight past the traffic light.</span><span class="sh">"</span><span class="s">
    3. </span><span class="sh">"</span><span class="s">Merge into the left lane.</span><span class="sh">"</span><span class="s">
    Generate an instruction that includes </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">:
    </span><span class="sh">"""</span>
</code></pre></div></div> <p>New prompt for multiple instructions:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_instruction_prompt</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate a prompt for the OpenAI API to create a driving instruction for a given action.
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
    Generate a short driving instruction that includes the action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">.
    Make sure each instruction is distinct and uses different wording or context. Here are some examples:
    </span><span class="sh">"</span><span class="s">Turn right at the next intersection.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Go straight past the traffic light.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Merge into the left lane.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">At the roundabout, take the second exit.</span><span class="sh">"</span><span class="s">
    </span><span class="sh">"</span><span class="s">Keep left to stay on the main road.</span><span class="sh">"</span><span class="s">
    There does not need to be any numerical numbering or any prefixes.
    Generate </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s"> unique instruction that include </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">:
    </span><span class="sh">"""</span>
</code></pre></div></div> <p>After testing, we found that the new prompt can significantly reduce the data generation time and there are almost no duplicate commands. This suggests that to generate data with similar structures, a more effective way to increase speed and avoid duplication is to generate a large batch of data at the prompt stage.</p> <h3 id="parallel-processing">Parallel Processing</h3> <p>Besides reducing the number of API calls, another method is to fully utilize the current Tier 2 parallel potential. Given the 3500 RPM of GPT-3.5-turbo, there is still more room for parallel processing. Parallel processing can fully utilize the capabilities of multi-core CPUs, reducing the overall processing time. Especially in network I/O intensive operations such as API calls, parallel processing can significantly reduce waiting time.</p> <p>By using <code class="language-plaintext highlighter-rouge">concurrent.futures.ThreadPoolExecutor</code>, parallel processing is achieved.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/optimized-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/optimized-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/optimized-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/optimized.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the optimized code, we combined the two methods mentioned above: using batch generation to reduce the number of API calls and using parallel processing to handle multiple batch generation requests simultaneously. The specific implementation steps are as follows:</p> <p><strong>Batch Generation of Commands:</strong></p> <p>Using the latest prompt mentioned above and passing in the <code class="language-plaintext highlighter-rouge">batch_size</code> parameter to generate multiple instructions at once. It is important to note that more tokens are needed (<code class="language-plaintext highlighter-rouge">max_tokens=10</code> in our case), and regular expressions should be used to handle any potential impurities in the data. For example, data entries like these: ”43. Proceed straight towards the tall building in the distance.“ or ”- Travel straight as the road bends to the left.” The following regex code can effectively remove impurities:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1"># Split multiple instructions from a single response
</span>    <span class="n">instructions</span> <span class="o">=</span> <span class="n">raw_instruction</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Remove leading numbers and punctuation from each instruction
</span>    <span class="n">instructions_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">^[\d\W]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">instruction</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">instruction</span> <span class="ow">in</span> <span class="n">instructions</span>
    <span class="p">]</span>
</code></pre></div></div> <p>In the <code class="language-plaintext highlighter-rouge">fetch_instructions</code> and <code class="language-plaintext highlighter-rouge">generate_instructions_batch</code> functions in <code class="language-plaintext highlighter-rouge">utils.py</code>, use the <code class="language-plaintext highlighter-rouge">n</code> parameter to generate multiple commands at once. This method was later removed because the prompt itself can generate a sufficient number of instructions.</p> <p><strong>Thread Pool:</strong></p> <p>In the <code class="language-plaintext highlighter-rouge">generate_dataset</code> function in <code class="language-plaintext highlighter-rouge">dataset_generator.py</code>, use <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> to parallelize the execution of multiple batch generation requests.</p> <p><code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> is used to manage concurrent tasks, where each task generates a batch of instructions for a given action. It ensures that a unique set of instructions is generated for each action, dynamically adjusting the batch size to ensure at least five samples per batch while not exceeding the maximum batch size. The tasks are submitted to the <code class="language-plaintext highlighter-rouge">executor</code>, and the future results are mapped to their respective actions for further processing.</p> <p>By default, <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> automatically determines the number of threads based on the system’s available resources. However, we can control the number of concurrent tasks more precisely by setting the thread pool size. If not specified, <code class="language-plaintext highlighter-rouge">ThreadPoolExecutor</code> will use a reasonable default value, usually <code class="language-plaintext highlighter-rouge">os.cpu_count()</code>.</p> <p>In addition to the core points mentioned above, there are other techniques that can be adopted.</p> <ol> <li><em>Reduce output token count</em></li> <li><em>Switch from GPT-4 to GPT-3.5</em></li> <li><em>Switch to Azure-hosted APIs</em></li> <li><em>Parallelize your calls</em></li> <li><em>Stream output and use stop sequences</em></li> </ol> <p>For more detailed information, you can refer to this blog: <a href="https://www.taivo.ai/__making-gpt-api-responses-faster/">Making GPT API Responses Faster</a></p> <p>Because the data structures we use are relatively simple, it’s easy to reduce the token count, and using GPT-3.5 is more cost-effective and faster.</p> <p>We used optimized methods to recreate the data and tested the generation efficiency under different conditions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="n">dataset_generator_batch_optimized</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">actions</span> <span class="n">Straight</span> <span class="n">Right</span> <span class="n">LaneFollow</span> <span class="n">Left</span> <span class="o">--</span><span class="n">num_samples</span> <span class="mi">1000</span> <span class="o">--</span><span class="n">output_file</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">user_instructions</span><span class="o">/</span><span class="n">dataset_4000</span><span class="p">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">100</span>
</code></pre></div></div> <table> <thead> <tr> <th>Instructions Generated</th> <th>Time (seconds)</th> </tr> </thead> <tbody> <tr> <td>500</td> <td>26.09</td> </tr> <tr> <td>1000</td> <td>44.97</td> </tr> <tr> <td>4000</td> <td>159.67</td> </tr> </tbody> </table> <p>In the previous method, generating 100 instructions took 158.48 seconds, and the data set stopped growing around 1k. With the new method, this limit can be easily surpassed, and the time to generate data has been significantly reduced.</p> <p>Here is the complete terminal output log for <code class="language-plaintext highlighter-rouge">dataset_4000.csv</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="n">dataset_generator_batch_optimized</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">actions</span> <span class="n">Straight</span> <span class="n">Right</span> <span class="n">LaneFollow</span> <span class="n">Left</span> <span class="o">--</span><span class="n">num_samples</span> <span class="mi">1000</span> <span class="o">--</span><span class="n">output_file</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">user_instructions</span><span class="o">/</span><span class="n">dataset_4000</span><span class="p">.</span><span class="n">csv</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">94</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">94</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">60</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">40</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">84</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">167</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">27</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">184</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">167</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">144</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">250</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">271</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">13</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">228</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">252</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">338</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">336</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">305</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">348</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">439</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">9</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">434</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">4</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">419</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">394</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">11</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">522</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">502</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">524</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">472</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">22</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">607</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">595</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">29</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">577</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">25</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">555</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">688</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">7</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">699</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">8</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">661</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">16</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">637</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">747</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">782</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">6</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">706</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">31</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">785</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">14</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">875</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">783</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">23</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">830</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">17</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">855</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">27</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">945</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">10</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">915</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">15</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">862</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">21</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">957</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">86</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1019</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">12</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">86</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1036</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">7</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1003</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">12</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">944</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1075</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">25</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Submitting</span> <span class="n">batch</span> <span class="n">generation</span> <span class="k">for</span> <span class="n">action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span> <span class="k">with</span> <span class="n">batch</span> <span class="n">size</span> <span class="mi">100</span>
<span class="n">Action</span> <span class="sh">'</span><span class="s">LaneFollow</span><span class="sh">'</span><span class="p">:</span> <span class="n">Generated</span> <span class="mi">1026</span> <span class="o">/</span> <span class="mi">1000</span> <span class="n">unique</span> <span class="nf">instructions </span><span class="p">(</span><span class="n">Discarded</span> <span class="mi">18</span> <span class="n">duplicates</span><span class="p">)</span>
<span class="n">Total</span> <span class="nf">discarded </span><span class="p">(</span><span class="n">duplicate</span><span class="p">)</span> <span class="n">instructions</span><span class="p">:</span> <span class="mi">813</span>
                                            <span class="n">instruction</span>      <span class="n">action</span>
<span class="mi">0</span>                                                    <span class="sh">""</span>  <span class="p">[</span><span class="n">Straight</span><span class="p">]</span>
<span class="mi">1</span>     <span class="sh">"</span><span class="s">Continue straight on this route until you see...  [Straight]
2             </span><span class="sh">"</span><span class="n">Go</span> <span class="n">straight</span> <span class="n">onto</span> <span class="n">the</span> <span class="n">highway</span> <span class="nb">exit</span> <span class="n">ramp</span><span class="p">.</span><span class="sh">"</span><span class="s">  [Straight]
3                    </span><span class="sh">"</span><span class="n">Head</span> <span class="n">straight</span> <span class="n">along</span> <span class="n">this</span> <span class="n">avenue</span><span class="p">.</span><span class="sh">"</span><span class="s">  [Straight]
4     </span><span class="sh">"</span><span class="n">Navigate</span> <span class="n">the</span> <span class="n">roundabout</span> <span class="ow">and</span> <span class="n">take</span> <span class="n">the</span> <span class="nb">exit</span> <span class="nb">str</span><span class="p">...</span>  <span class="p">[</span><span class="n">Straight</span><span class="p">]</span>
<span class="p">...</span>                                                 <span class="p">...</span>         <span class="bp">...</span>
<span class="mi">3995</span>  <span class="sh">"</span><span class="s">Watch for any obstructions on the left side o...      [Left]
3996               </span><span class="sh">"</span><span class="n">Signal</span> <span class="n">left</span> <span class="n">before</span> <span class="n">changing</span> <span class="n">lanes</span><span class="p">.</span><span class="sh">"</span><span class="s">      [Left]
3997              </span><span class="sh">"</span><span class="n">Stay</span> <span class="n">left</span> <span class="n">to</span> <span class="n">enter</span> <span class="n">the</span> <span class="n">parking</span> <span class="n">lot</span><span class="p">.</span><span class="sh">"</span><span class="s">      [Left]
3998  </span><span class="sh">"</span><span class="n">Merge</span> <span class="n">into</span> <span class="n">the</span> <span class="n">left</span> <span class="n">lane</span> <span class="k">for</span> <span class="n">the</span> <span class="n">upcoming</span> <span class="n">lef</span><span class="p">...</span>      <span class="p">[</span><span class="n">Left</span><span class="p">]</span>
<span class="mi">3999</span>              <span class="sh">"</span><span class="s">Proceed left at the T-intersection.</span><span class="sh">"</span>      <span class="p">[</span><span class="n">Left</span><span class="p">]</span>

<span class="p">[</span><span class="mi">4000</span> <span class="n">rows</span> <span class="n">x</span> <span class="mi">2</span> <span class="n">columns</span><span class="p">]</span>
<span class="n">Dataset</span> <span class="n">generated</span> <span class="ow">and</span> <span class="n">saved</span> <span class="n">to</span> <span class="sh">'</span><span class="s">./datasets/user_instructions/dataset_4000.csv</span><span class="sh">'</span>
<span class="n">Generated</span> <span class="mi">4000</span> <span class="n">instructions</span> <span class="ow">in</span> <span class="mf">159.67</span> <span class="n">seconds</span><span class="p">.</span>
</code></pre></div></div> <p>Word cloud map analysis of the dataset</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/word_cloud_714-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/word_cloud_714-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/word_cloud_714-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/word_cloud_714.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="conclusion">Conclusion</h3> <p>For generating similar types of instruction data, a more efficient approach is:</p> <ul> <li>Deduplication: Instruct the model to generate multiple unique pieces of data in a single prompt, rather than using the same prompt multiple times and then deduplicating, as this does not improve the quality of the data.</li> <li>Acceleration: Reduce the number of requests, increase the amount generated per request, and use parallel processing.</li> </ul> <p>The above test results are based on a not fully optimized setup. I believe further optimization is possible. This method is scalable in terms of data. Regarding performance, one of the biggest impacts is <code class="language-plaintext highlighter-rouge">num_threads</code>; I currently use around 10. Additionally, for <code class="language-plaintext highlighter-rouge">max_batch_size</code>, I generally use 100.</p> <p>It is also worth noting that the development cost is relatively affordable. Throughout the entire development cycle, my API usage bill did not exceed $10.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/api_usage-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/api_usage-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/api_usage-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/api_usage.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting During the July 10 meeting, we focused on refining our dataset and integrating our models into the overall framework. We discussed the use of iterative generation techniques to remove duplicated lines from our datasets, aiming to establish a robust baseline for our project. We also explored the implementation of high-level commands with text inputs for the model.]]></summary></entry><entry><title type="html">Coding week6 7/01-7/07</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-7-01-7-07/" rel="alternate" type="text/html" title="Coding week6 7/01-7/07"/><published>2024-07-07T00:00:00+00:00</published><updated>2024-07-07T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week6</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-7-01-7-07/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>Our follow-up meeting on June 26 continued addressing critical issues. I led a discussion on unbalanced datasets and implemented simple and complex instructions. We explored the use of a BERT model for instruction classification, agreeing on the importance of dividing datasets into training and testing sets to ensure robust metrics. A key outcome was removing duplicated lines from datasets using iterative generation techniques. We plan to integrate the BERT model with the refined dataset and incorporate it into the overall framework to establish our first baseline. Sergio proposed two approaches: utilizing Qi’s model for action decoding and aiming towards a step forward with the LMDrive model.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="sample-route">Sample Route</h3> <p>The <code class="language-plaintext highlighter-rouge">sample_route</code> function randomly selects a route from the provided <code class="language-plaintext highlighter-rouge">episode_configs</code> file. Let’s break down this function step by step to understand how the route is generated and what it contains.</p> <p>First, let’s look at the code for the <code class="language-plaintext highlighter-rouge">sample_route</code> function:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sample_route</span><span class="p">(</span><span class="n">world</span><span class="p">,</span> <span class="n">episode_configs</span><span class="p">):</span>
    <span class="n">spawn_points</span> <span class="o">=</span> <span class="n">world</span><span class="p">.</span><span class="nf">get_map</span><span class="p">().</span><span class="nf">get_spawn_points</span><span class="p">()</span>
    <span class="n">episode_config</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">episode_configs</span><span class="p">)</span>
    <span class="n">start_point</span> <span class="o">=</span> <span class="n">spawn_points</span><span class="p">[</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">end_point</span> <span class="o">=</span> <span class="n">spawn_points</span><span class="p">[</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">from spawn point #</span><span class="si">{</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s"> to #</span><span class="si">{</span><span class="n">episode_config</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">route_length</span> <span class="o">=</span> <span class="n">episode_config</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">route</span> <span class="o">=</span> <span class="n">episode_config</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">copy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">episode_config</span><span class="p">,</span> <span class="n">start_point</span><span class="p">,</span> <span class="n">end_point</span><span class="p">,</span> <span class="n">route_length</span><span class="p">,</span> <span class="n">route</span>
</code></pre></div></div> <p>The given <code class="language-plaintext highlighter-rouge">episode_configs</code> file contains multiple lines of data, each representing a route and its associated high-level commands. Each line follows this format:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Start Index End Index Route Length High-Level Command1 High-Level Command2
</code></pre></div></div> <p>For example, the first line of data is:</p> <div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">24</span> <span class="err">79</span> <span class="err">158</span> <span class="nt">Right</span> <span class="nt">Right</span>
</code></pre></div></div> <p>This means:</p> <ul> <li>Start Index: 24</li> <li>End Index: 79</li> <li>Route Length: 158</li> <li>High-Level Commands: Right, Right</li> </ul> <h3 id="contents-of-the-route">Contents of the <code class="language-plaintext highlighter-rouge">route</code></h3> <p>The <code class="language-plaintext highlighter-rouge">route</code> contains a series of high-level commands, which are the vehicle’s turning instructions at intersections along the route. For example, the <code class="language-plaintext highlighter-rouge">route</code> value might be <code class="language-plaintext highlighter-rouge">['Right', 'Right']</code>, indicating that the vehicle should turn right at the first intersection and right again at the second intersection.</p> <p>In the subsequent simulation process, these return values will be used to initialize the vehicle’s position, determine its travel route, and guide the vehicle’s turns at intersections through high-level commands.</p> <h3 id="why-use-imitation-learning">Why Use Imitation Learning?</h3> <p>In the paper “End-to-end Driving via Conditional Imitation Learning,” the authors address the limitations and challenges of imitation learning for autonomous urban driving. The primary motivation for this work is to overcome the inherent difficulties in mapping perceptual inputs directly to control commands, especially in complex driving scenarios.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/imitation-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/imitation-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/imitation-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/imitation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Imitation learning aims to train models by mimicking human actions, which in theory, should enable the model to perform tasks similarly to how a human would. However, this approach faces several significant challenges:</p> <p>Optimal Action Inference:</p> <p>The assumption that the optimal action (a_t) can be inferred solely from the perceptual input (o_t) is often flawed. As highlighted in the text, this is particularly problematic when a car approaches an intersection. The camera input alone is insufficient to predict whether the car should turn left, right, or go straight. This scenario illustrates that additional context or commands ((c_t)) are necessary for accurate decision-making.</p> <p>Function Approximation Difficulties:</p> <p>The mapping from image to control command is not always a straightforward function. This complexity is exacerbated in real-world environments where multiple plausible actions can exist for a given situation. For instance, as mentioned in the paper, when a network reaches a fork, it may output two widely discrepant travel directions, one for each possible choice. This results in oscillations and instability in the dictated travel direction.</p> <p>The high-level overview in this Figure demonstrates the interaction between the controller and the environment:</p> <ul> <li><strong>Observation ((o_t))</strong>: The controller receives observations from the environment, which are the sensory inputs, such as images from cameras.</li> <li><strong>Command ((c_t))</strong>: The controller also receives high-level commands that provide context, such as “turn left” or “go straight.”</li> <li><strong>Action ((a_t))</strong>: Based on the observation and command, the controller produces an action that affects the environment.</li> <li><strong>Next Observation ((o_{t+1}))</strong>: The action results in a change in the environment, leading to the next observation.</li> </ul> <p>The figure underscores the necessity of combining both perceptual inputs and high-level commands to generate appropriate actions.</p> <h3 id="highlevelcommandloader">HighLevelCommandLoader</h3> <p>The <code class="language-plaintext highlighter-rouge">HighLevelCommandLoader</code> is designed to provide turn-by-turn instructions for a vehicle navigating through intersections. These instructions can either be predefined or selected randomly based on real-time intersection detection.</p> <p>Example Configuration</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 Right Right
77 1 166 Left Left
32 75 174 Right Straight
76 33 193 Straight Left
52 59 148 Left Right
69 51 136 Left Right
40 69 272 Straight Left
59 39 245 Right Straight
60 25 255 Straight Right
23 61 269 Left Straight
82 17 155 Right Left
18 83 140 Right Left
</code></pre></div></div> <p>Route Initialization:</p> <p>When initializing <code class="language-plaintext highlighter-rouge">HighLevelCommandLoader</code>, the route is provided:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc_loader</span> <span class="o">=</span> <span class="nc">HighLevelCommandLoader</span><span class="p">(</span><span class="n">vehicle</span><span class="p">,</span> <span class="n">world</span><span class="p">.</span><span class="nf">get_map</span><span class="p">(),</span> <span class="n">route</span><span class="p">)</span>
</code></pre></div></div> <p>Fetching High-Level Commands:</p> <p>In each simulation step, the next high-level command is fetched:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc</span> <span class="o">=</span> <span class="n">hlc_loader</span><span class="p">.</span><span class="nf">get_next_hlc</span><span class="p">()</span>
</code></pre></div></div> <p>Loading Next High-Level Command:</p> <p>If the vehicle is at an intersection and there is a predefined route, <code class="language-plaintext highlighter-rouge">load_next_hlc</code> loads the next command:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hlc</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">route</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div> <p>If there is no predefined route, <code class="language-plaintext highlighter-rouge">get_random_hlc</code> randomly selects a command.</p> <h3 id="command-mapping">Command Mapping</h3> <p>Commands guide the vehicle’s behavior at intersections, ensuring it navigates according to the defined or random directions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">command</span><span class="p">):</span>
    <span class="n">commands</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">Left</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Right</span><span class="sh">'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">Straight</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">commands</span><span class="p">[</span><span class="n">command</span><span class="p">]</span>
</code></pre></div></div> <h3 id="integration-with-bert-model">Integration with BERT Model</h3> <ol> <li> <p><strong>Input Example:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="sh">"</span><span class="s">Make a left turn at the upcoming junction.</span><span class="sh">"</span>
</code></pre></div> </div> </li> <li> <p><strong>Tokenization:</strong></p> <ul> <li>The command is split into tokens and converted into a tensor of token IDs.</li> </ul> </li> <li> <p><strong>Prediction:</strong></p> <ul> <li>The token IDs are passed through the BERT model.</li> <li>The model outputs logits for each possible action class.</li> </ul> </li> </ol> <h3 id="modified-command-to-integer-mapping-with-bert">Modified Command-to-Integer Mapping with BERT</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_command_to_int</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">command</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tokenizer</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>

    <span class="c1"># Map predicted_class to corresponding actions
</span>    <span class="n">command_mapping</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># Left
</span>        <span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Right
</span>        <span class="mi">2</span><span class="p">:</span> <span class="mi">3</span>   <span class="c1"># Straight
</span>    <span class="p">}</span>

    <span class="k">return</span> <span class="n">command_mapping</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h3 id="example-flow">Example Flow</h3> <ol> <li><strong>Input:</strong> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="s2">"Make a left turn at the upcoming junction."</span>
</code></pre></div> </div> </li> <li> <p><strong>Processing:</strong></p> <ul> <li><strong>Tokenization:</strong> <ul> <li>Split the command into tokens.</li> <li>Convert tokens into tensor IDs.</li> </ul> </li> <li><strong>Prediction:</strong> <ul> <li>Pass tensor IDs through the BERT model.</li> <li>Obtain logits for action classes.</li> </ul> </li> </ul> </li> <li> <p><strong>Actions:</strong></p> <ul> <li><strong>Mapping:</strong> <ul> <li>Map predicted action class to predefined actions: <code class="language-plaintext highlighter-rouge">Left (1)</code>, <code class="language-plaintext highlighter-rouge">Right (2)</code>, <code class="language-plaintext highlighter-rouge">Straight (3)</code>.</li> </ul> </li> </ul> </li> </ol> <h3 id="data-mapping-example">Data Mapping Example</h3> <p>Input Data:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 Right Right
77 1 166 Left Left
32 75 174 Right Straight
76 33 193 Straight Left
52 59 148 Left Right
69 51 136 Left Right
40 69 272 Straight Left
59 39 245 Right Straight
60 25 255 Straight Right
23 61 269 Left Straight
82 17 155 Right Left
18 83 140 Right Left
</code></pre></div></div> <p>Mapped Commands:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
77 1 166 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
32 75 174 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
76 33 193 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
52 59 148 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
69 51 136 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
40 69 272 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
59 39 245 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
60 25 255 <span class="s2">"Continue straight at the upcoming junction."</span> <span class="s2">"Make a right turn at the upcoming junction."</span>
23 61 269 <span class="s2">"Make a left turn at the upcoming junction."</span> <span class="s2">"Continue straight at the upcoming junction."</span>
82 17 155 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
18 83 140 <span class="s2">"Make a right turn at the upcoming junction."</span> <span class="s2">"Make a left turn at the upcoming junction."</span>
</code></pre></div></div> <p>Annotated Example:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>24 79 158 <span class="s2">"Make a right turn at the upcoming stop sign."</span> <span class="s2">"Merge onto the highway and take the second right exit."</span>
77 1 166 <span class="s2">"Make a left turn at the second stop sign."</span> <span class="s2">"Take the left turn onto Main Street at the upcoming intersection."</span>
32 75 174 <span class="s2">"Make a sharp right turn onto Maple Street."</span> <span class="s2">"Continue straight on the highway for the next 10 miles."</span>
76 33 193 <span class="s2">"Continue straight on the highway for the next 10 miles."</span> <span class="s2">"Make a left turn at the upcoming stop sign."</span>
52 59 148 <span class="s2">"Make a left turn at the upcoming roundabout."</span> <span class="s2">"Make a right turn at the stop sign ahead."</span>
69 51 136 <span class="s2">"Make a left turn at the upcoming stop sign."</span> <span class="s2">"Make a right turn onto Main Street after the gas station."</span>
40 69 272 <span class="s2">"Continue straight on the highway for the next 10 miles."</span> <span class="s2">"Make a left turn at the upcoming roundabout."</span>
59 39 245 <span class="s2">"Merge onto the highway and take the next right exit."</span> <span class="s2">"Continue straight on the highway for the next 10 miles."</span>
60 25 255 <span class="s2">"Continue driving straight on this road for two more miles."</span> <span class="s2">"Make a right turn onto Maple Street after the stop sign."</span>
23 61 269 <span class="s2">"Make a left turn at the stop sign ahead."</span> <span class="s2">"Continue straight on the highway for the next 5 miles."</span>
82 17 155 <span class="s2">"Make a right turn onto Main Street after passing the gas station on your left."</span> <span class="s2">"Make a left turn at the upcoming stop sign."</span>
18 83 140 <span class="s2">"Make a right turn onto Elm Street after the bridge."</span> <span class="s2">"Make a left turn at the stop sign ahead."</span>
</code></pre></div></div> <h3 id="next-steps">Next Steps</h3> <ol> <li><strong>Retrain the BERT Model</strong></li> <li><strong>Install the Simulator</strong></li> <li><strong>Integrate and Test with the Simulator</strong></li> </ol>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week345 6/10-6/30</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-6-10-6-30/" rel="alternate" type="text/html" title="Coding week345 6/10-6/30"/><published>2024-06-30T00:00:00+00:00</published><updated>2024-06-30T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week345</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week345-6-10-6-30/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>In our recent meeting, we focused on enhancing our instruction generation process. I highlighted issues with data distribution, particularly the high similarity in GPT-generated data. To tackle this, we discussed strategies to balance our datasets, aiming to reduce redundancy and improve the diversity of the generated outputs. Sergio provided insights from previous projects, reviewing four key commands and proposing additional commands to enhance our current project’s functionality and efficiency. Additionally, we evaluated the metrics for our BERT model, agreeing that dividing the dataset into testing and training sets could yield acceptable results.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="data-generation">Data Generation</h3> <p>Currently, although our dataset is relatively balanced, the randomness of the data is not high, leading to a significant amount of duplicate data. To address this issue and improve the diversity of GPT-generated instructions, we’ve identified several solutions:</p> <p>Solution 1: Adjusting Parameters for Diversity</p> <p>By fine-tuning the <code class="language-plaintext highlighter-rouge">temperature</code> and <code class="language-plaintext highlighter-rouge">top_p</code> parameters, we can enhance the diversity of generated instructions. The temperature parameter controls the randomness of predictions by scaling the logits before applying softmax. A higher temperature results in more random outputs. The <code class="language-plaintext highlighter-rouge">top_p</code> parameter, also known as nucleus sampling, which ensures that the model considers only the <code class="language-plaintext highlighter-rouge">top p fraction</code> of cumulative probability mass, thus allowing for a more focused yet diverse set of outputs. By carefully balancing these parameters, we can generate a broader range of unique instructions.</p> <p>Solution 2: Increasing the Number of Samples Generated</p> <p>Generating a larger number of samples and then filtering out unique instructions can effectively increase diversity. This approach includes:</p> <ul> <li>Generating More Samples: Produce a higher volume of samples than needed, ensuring a wide variety of potential instructions.</li> <li>Dynamic Batch Size: Implement a dynamic batch size that adjusts according to the remaining number of samples to be generated. To avoid hard-coding the batch size, it is set to twice the number of remaining samples, but not exceeding 50. This flexibility ensures efficient use of resources while maintaining the target number of unique instructions.</li> <li>Collection De-duplication: Utilize collection auto-de-duplication to filter out duplicate instructions. After de-duplication, limit the collection to the desired number of unique instructions. This process ensures that the final set of instructions is both diverse and manageable.</li> </ul> <p>Solution 3: Adding Contextual Information</p> <p>Incorporating more contextual information into the prompts can help the model generate more diverse instructions. Providing detailed context allows the model to understand the nuances of the task better, leading to richer and more varied outputs. This could involve including specific scenarios, additional background information, or detailed task descriptions within the prompts. By doing so, we enable the model to generate instructions that are not only diverse but also more relevant and contextually appropriate.</p> <h3 id="iteration-method-example">Iteration Method Example</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/iter-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/iter-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/iter-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/iter.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In one iteration, generating unique instructions for the action ‘LaneFollow’ involved multiple steps.</p> <p>Similarly, generating instructions for actions like ‘Left’, ‘Right’, and ‘Straight’ required repeated attempts to reach the desired count of unique instructions, resulting in high redundancy and a longer processing time.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 1 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 2 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 3 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 4 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 5 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 6 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 7 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 8 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 9 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 10 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 11 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 12 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 13 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 14 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 15 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 16 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 18 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 20 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 24 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 25 / 25 unique instructions
                                          instruction        action
0   <span class="s2">"Enter the highway and LaneFollow the middle l...  [LaneFollow]
1   "</span>Continue straight on Main Street and LaneFoll...  <span class="o">[</span>LaneFollow]
2   <span class="s2">"Enter the highway and LaneFollow the traffic ...  [LaneFollow]
3   "</span>Enter the highway and LaneFollow the traffic ...  <span class="o">[</span>LaneFollow]
4   <span class="s2">"Once you enter the highway, activate LaneFoll...  [LaneFollow]
..                                                ...           ...
95  "</span>Continue driving straight on Main Street <span class="k">for</span> ...    <span class="o">[</span>Straight]
96    <span class="s2">"Continue straight on the highway for 5 miles."</span>    <span class="o">[</span>Straight]
97  <span class="s2">"Continue driving straight on Main Street for ...    [Straight]
98  "</span>Continue driving straight on this road <span class="k">for </span>an...    <span class="o">[</span>Straight]
99  <span class="s2">"Continue driving straight on this road for tw...    [Straight]

[100 rows x 2 columns]
Dataset generated and saved to 'dataset_1000.csv'
Generated 100 instructions in 221.16 seconds.
</span></code></pre></div></div> <h3 id="batch-method-example">Batch Method Example</h3> <p>By contrast, using a batch method improves efficiency and reduces redundancy. For example:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/batch-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/batch-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/batch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/batch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 19 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 21 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 22 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Left'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Right'</span>: Generated 25 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 23 / 25 unique instructions
Action <span class="s1">'Straight'</span>: Generated 25 / 25 unique instructions
                                          instruction        action
0   <span class="s2">"LaneFollow the vehicle in front of you as you...  [LaneFollow]
1   "</span>Continue LaneFollow on the highway <span class="k">for </span>the ne...  <span class="o">[</span>LaneFollow]
2   <span class="s2">"Once on the highway, LaneFollow and maintain ...  [LaneFollow]
3   "</span>Enter the highway and LaneFollow the middle l...  <span class="o">[</span>LaneFollow]
4   <span class="s2">"Stay in the right lane and LaneFollow the veh...  [LaneFollow]
..                                                ...           ...
95  "</span>Continue straight on the highway <span class="k">for </span>5 miles ...    <span class="o">[</span>Straight]
96  <span class="s2">"Continue straight on this road for the next 2...    [Straight]
97  "</span>Continue straight on the highway <span class="k">for </span>another ...    <span class="o">[</span>Straight]
98  <span class="s2">"Continue driving straight on this road for th...    [Straight]
99  "</span>Continue driving straight on the highway <span class="k">for</span> ...    <span class="o">[</span>Straight]

<span class="o">[</span>100 rows x 2 columns]
Dataset generated and saved to <span class="s1">'dataset_1000.csv'</span>
Generated 100 instructions <span class="k">in </span>158.48 seconds.
</code></pre></div></div> <p>The batch method resulted in fewer duplicate instructions and a significant improvement in processing time.</p> <ul> <li>Iteration Method: Generated 100 instructions with <strong>521</strong> duplicates in <strong>221.16</strong> seconds.</li> <li>Batch Method: Generated 100 instructions with <strong>122</strong> duplicates in <strong>158.48</strong> seconds.</li> </ul> <p>The batch method improved efficiency by <strong>28.34%</strong> and reduced duplicates by <strong>326.23%</strong> compared to the iteration method.</p> <h3 id="data-analysis">Data Analysis</h3> <p>In addition to optimizing the generation of instructions, I performed an analysis of the data distribution and created a word cloud to visualize the most frequently occurring terms. This analysis helped us understand the underlying patterns in the dataset and identify areas for improvement.</p> <p>Data Distribution Analysis</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/data_distribution_630-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/data_distribution_630-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/data_distribution_630-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/data_distribution_630.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>By examining the distribution of instructions across different actions, we identified four actions are balanced.</p> <p>Word Cloud</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/word_cloud_630-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/word_cloud_630-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/word_cloud_630-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/word_cloud_630.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The word cloud provided a visual representation of the most common terms in our dataset. Words like “continue,” “straight,” “left,” and “right” appeared frequently, indicating their prominence in the instructions. This visualization highlighted the need to diversify the vocabulary used in the generated instructions to enhance the overall richness and utility of the dataset.</p> <h3 id="scalable-of-datasets">Scalable of Datasets</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Action </span><span class="sh">'</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="sh">'</span><span class="s">: Generated </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">unique_instructions</span><span class="p">)</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">num_samples_per_action</span><span class="si">}</span><span class="s"> unique instructions</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Action <span class="s1">'LaneFollow'</span>: Generated 43 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 76 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 112 / 125 unique instructions
Action <span class="s1">'LaneFollow'</span>: Generated 125 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 17 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 26 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 31 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 33 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 40 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 44 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 47 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 50 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 50 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 51 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 54 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 55 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 57 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 58 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 60 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 61 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 63 / 125 unique instructions
Action <span class="s1">'Left'</span>: Generated 65 / 125 unique instructions
</code></pre></div></div> <p>The implication of our current approach is that approximately 98% of the instructions generated in each batch will be discarded. This high discard rate indicates an inherent limitation in the method, where repeated looping of a prompt leads to a significant number of duplicate instructions. This issue highlights the challenges associated with maintaining diversity and uniqueness in large-scale instruction generation.</p> <p>While we have successfully addressed issues related to small-scale data generation, balancing the dataset, and reducing data duplication, the challenge of data scaling remains unresolved. Scaling up our data generation processes without compromising diversity and quality is a complex problem that requires further exploration. If there is a demand for online large-scale data generation, we will need to develop and implement new strategies to handle these challenges. This may involve advanced techniques for dynamic prompt generation, more sophisticated filtering algorithms, and possibly leveraging real-time data augmentation methods to ensure a continuous stream of unique and varied instructions.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Coding week2 6/03-6/09</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week2-6-03-6-09/" rel="alternate" type="text/html" title="Coding week2 6/03-6/09"/><published>2024-06-24T00:00:00+00:00</published><updated>2024-06-24T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week2</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week2-6-03-6-09/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>In this week’s meeting, we reviewed our project’s current status. We analyzed the high similarity observed in the outputs generated by GPT and discussed the issues of data distribution, which led to redundancy. To address these concerns, we brainstormed strategies to enhance the diversity and balance of our dataset. Additionally, we revisited four key commands from our previous project and explored how integrating more commands could boost both functionality and efficiency. We also deliberated on setting appropriate metrics for the BERT model by segmenting the dataset into training and testing sets.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="to-do-list">To-Do List</h3> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Generate scalable datasets that are intertwined with actions and commands with LLMs.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Perform quality analyses on the generated datasets.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Train the Bert model to classify instructions and obtain a model.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Move training and test notebooks in gsoc23 to a separate script. <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/5">issue</a></li> </ul> <h3 id="progress">Progress</h3> <p>This week, I developed a module designed to generate user-driving instructions using GPT. The code focuses on creating prompts based on predefined templates and user inputs, with an emphasis on improving the logic for prompt creation to enhance clarity and engagement. Additionally, the module includes features for validating user inputs and adjusting the output format accordingly. This advancement is beneficial for providing scalable instruction datasets in our project.</p> <p>The module also implements an action generation component, which formulates specific actions based on the instructions generated by GPT, such as “turn left,” “turn right,” “take exit,” “go straight,” “accelerate,” and “slow down.” Furthermore, I developed analytical tools within the prompt_analysis.py script to evaluate the effectiveness of the generated instructions, incorporating metrics to assess their relevance. Lastly, I implemented training using the BERT model to further enhance the module’s performance.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python train.py
1000 1000
Labels length: 1000
Input IDs length: 1000
Attention Mask length: 1000
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: <span class="o">[</span><span class="s1">'classifier.bias'</span>, <span class="s1">'classifier.weight'</span><span class="o">]</span>
You should probably TRAIN this model on a down-stream task to be able to use it <span class="k">for </span>predictions and inference.
<span class="o">{</span><span class="s1">'loss'</span>: 1.697, <span class="s1">'grad_norm'</span>: 19.306570053100586, <span class="s1">'learning_rate'</span>: 1.0000000000000002e-06, <span class="s1">'epoch'</span>: 0.09<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.617, <span class="s1">'grad_norm'</span>: 13.708064079284668, <span class="s1">'learning_rate'</span>: 2.0000000000000003e-06, <span class="s1">'epoch'</span>: 0.18<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.4665, <span class="s1">'grad_norm'</span>: 9.595329284667969, <span class="s1">'learning_rate'</span>: 3e-06, <span class="s1">'epoch'</span>: 0.27<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.2224, <span class="s1">'grad_norm'</span>: 12.889700889587402, <span class="s1">'learning_rate'</span>: 4.000000000000001e-06, <span class="s1">'epoch'</span>: 0.35<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 1.0262, <span class="s1">'grad_norm'</span>: 10.967733383178711, <span class="s1">'learning_rate'</span>: 5e-06, <span class="s1">'epoch'</span>: 0.44<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.7739, <span class="s1">'grad_norm'</span>: 13.827258110046387, <span class="s1">'learning_rate'</span>: 6e-06, <span class="s1">'epoch'</span>: 0.53<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.7852, <span class="s1">'grad_norm'</span>: 5.5881853103637695, <span class="s1">'learning_rate'</span>: 7.000000000000001e-06, <span class="s1">'epoch'</span>: 0.62<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.6525, <span class="s1">'grad_norm'</span>: 8.820500373840332, <span class="s1">'learning_rate'</span>: 8.000000000000001e-06, <span class="s1">'epoch'</span>: 0.71<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3866, <span class="s1">'grad_norm'</span>: 4.9470295906066895, <span class="s1">'learning_rate'</span>: 9e-06, <span class="s1">'epoch'</span>: 0.8<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3203, <span class="s1">'grad_norm'</span>: 3.308020830154419, <span class="s1">'learning_rate'</span>: 1e-05, <span class="s1">'epoch'</span>: 0.88<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3612, <span class="s1">'grad_norm'</span>: 9.319038391113281, <span class="s1">'learning_rate'</span>: 1.1000000000000001e-05, <span class="s1">'epoch'</span>: 0.97<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3051, <span class="s1">'grad_norm'</span>: 8.626148223876953, <span class="s1">'learning_rate'</span>: 1.2e-05, <span class="s1">'epoch'</span>: 1.06<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3143, <span class="s1">'grad_norm'</span>: 4.779806613922119, <span class="s1">'learning_rate'</span>: 1.3000000000000001e-05, <span class="s1">'epoch'</span>: 1.15<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2742, <span class="s1">'grad_norm'</span>: 8.452868461608887, <span class="s1">'learning_rate'</span>: 1.4000000000000001e-05, <span class="s1">'epoch'</span>: 1.24<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3953, <span class="s1">'grad_norm'</span>: 3.7451024055480957, <span class="s1">'learning_rate'</span>: 1.5e-05, <span class="s1">'epoch'</span>: 1.33<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2989, <span class="s1">'grad_norm'</span>: 0.8715028762817383, <span class="s1">'learning_rate'</span>: 1.6000000000000003e-05, <span class="s1">'epoch'</span>: 1.42<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.3149, <span class="s1">'grad_norm'</span>: 9.316072463989258, <span class="s1">'learning_rate'</span>: 1.7000000000000003e-05, <span class="s1">'epoch'</span>: 1.5<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1399, <span class="s1">'grad_norm'</span>: 8.054197311401367, <span class="s1">'learning_rate'</span>: 1.8e-05, <span class="s1">'epoch'</span>: 1.59<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.246, <span class="s1">'grad_norm'</span>: 7.560857772827148, <span class="s1">'learning_rate'</span>: 1.9e-05, <span class="s1">'epoch'</span>: 1.68<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.151, <span class="s1">'grad_norm'</span>: 0.3591634929180145, <span class="s1">'learning_rate'</span>: 2e-05, <span class="s1">'epoch'</span>: 1.77<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1007, <span class="s1">'grad_norm'</span>: 7.88149881362915, <span class="s1">'learning_rate'</span>: 2.1e-05, <span class="s1">'epoch'</span>: 1.86<span class="o">}</span>
 63%|█████████████████████████████████████████████████████████████████████████████████▏                                              | 215/33 64%|████████████████████████████████████████████████████████████████▉                                     | 216/339 <span class="o">[</span>00:55&lt;00:31,  3.93it/s]<span class="o">{</span><span class="s1">'loss'</span>: 0.1223, <span class="s1">'grad_norm'</span>: 1.4635449647903442, <span class="s1">'learning_rate'</span>: 2.2000000000000003e-05, <span class="s1">'epoch'</span>: 1.95<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1039, <span class="s1">'grad_norm'</span>: 17.848655700683594, <span class="s1">'learning_rate'</span>: 2.3000000000000003e-05, <span class="s1">'epoch'</span>: 2.04<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2297, <span class="s1">'grad_norm'</span>: 0.22711549699306488, <span class="s1">'learning_rate'</span>: 2.4e-05, <span class="s1">'epoch'</span>: 2.12<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2394, <span class="s1">'grad_norm'</span>: 0.3263954222202301, <span class="s1">'learning_rate'</span>: 2.5e-05, <span class="s1">'epoch'</span>: 2.21<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2566, <span class="s1">'grad_norm'</span>: 0.4583888351917267, <span class="s1">'learning_rate'</span>: 2.6000000000000002e-05, <span class="s1">'epoch'</span>: 2.3<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1733, <span class="s1">'grad_norm'</span>: 0.12949731945991516, <span class="s1">'learning_rate'</span>: 2.7000000000000002e-05, <span class="s1">'epoch'</span>: 2.39<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1403, <span class="s1">'grad_norm'</span>: 0.12070054560899734, <span class="s1">'learning_rate'</span>: 2.8000000000000003e-05, <span class="s1">'epoch'</span>: 2.48<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2578, <span class="s1">'grad_norm'</span>: 0.15354938805103302, <span class="s1">'learning_rate'</span>: 2.9e-05, <span class="s1">'epoch'</span>: 2.57<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1055, <span class="s1">'grad_norm'</span>: 0.30441755056381226, <span class="s1">'learning_rate'</span>: 3e-05, <span class="s1">'epoch'</span>: 2.65<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2079, <span class="s1">'grad_norm'</span>: 16.82185935974121, <span class="s1">'learning_rate'</span>: 3.1e-05, <span class="s1">'epoch'</span>: 2.74<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.2025, <span class="s1">'grad_norm'</span>: 4.622957229614258, <span class="s1">'learning_rate'</span>: 3.2000000000000005e-05, <span class="s1">'epoch'</span>: 2.83<span class="o">}</span>
<span class="o">{</span><span class="s1">'loss'</span>: 0.1915, <span class="s1">'grad_norm'</span>: 18.763633728027344, <span class="s1">'learning_rate'</span>: 3.3e-05, <span class="s1">'epoch'</span>: 2.92<span class="o">}</span>
<span class="o">{</span><span class="s1">'train_runtime'</span>: 84.7519, <span class="s1">'train_samples_per_second'</span>: 31.858, <span class="s1">'train_steps_per_second'</span>: 4.0, <span class="s1">'train_loss'</span>: 0.45582248397984687, <span class="s1">'epoch'</span>: 3.0<span class="o">}</span>
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 339/339 <span class="o">[</span>01:24&lt;00:00,  4.00it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 <span class="o">[</span>00:00&lt;00:00, 11.49it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 <span class="o">[</span>00:00&lt;00:00, 11.14it/s]
              precision    recall  f1-score   support

           0       0.99      0.96      0.97        89
           1       0.71      0.91      0.80        11

    accuracy                           0.95       100
   macro avg       0.85      0.93      0.89       100
weighted avg       0.96      0.95      0.95       100
</code></pre></div></div> <h3 id="challenges">Challenges</h3> <p>During the data generation process, I encountered a significant issue with data imbalance. By using GPT to generate 1000 data points, I discovered that the distribution of the data was uneven, as illustrated below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/wordcloud-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/wordcloud-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/wordcloud-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/wordcloud.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/datasets-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/datasets-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/datasets-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/datasets.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/gsoc2024-ZebinHuang/assets/img/distribution-480.webp 480w,/gsoc2024-ZebinHuang/assets/img/distribution-800.webp 800w,/gsoc2024-ZebinHuang/assets/img/distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/gsoc2024-ZebinHuang/assets/img/distribution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>From the database analysis, we observed an increased presence of data duplicates, such as the instruction “Approaching the roundabout.” Consequently, the model’s interpretation of this instruction has predominantly skewed towards “take exit.” This repetition is also evident in the word cloud, where several words appear repeatedly. This issue results in an unbalanced distribution of data, which affects the model’s performance and accuracy in understanding diverse driving instructions.</p> <p>Although the BERT model achieved satisfactory accuracy, the skewed data distribution poses challenges for real-world application. The model’s performance might not generalize well to new, unseen data if it does not reflect a balanced representation of all possible scenarios. This imbalance could lead to biased predictions and reduced effectiveness in practical use cases. Addressing this challenge will be crucial to ensure the robustness and reliability of the instructional generation system. Potential solutions include augmenting the dataset to ensure balance or applying bias correction methods during the model training phase.</p> <h3 id="future-tasks">Future Tasks</h3> <ul> <li>Continue refining the data balancing strategies to further improve the diversity of generated outputs.</li> <li>Complete the integration and testing of additional commands from previous projects.</li> <li>Optimize the model training process and evaluate the effectiveness of the dataset division.</li> </ul>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Set up CARLA with Docker</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/carla-docker/" rel="alternate" type="text/html" title="Set up CARLA with Docker"/><published>2024-06-10T00:00:00+00:00</published><updated>2024-06-10T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/carla-docker</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/carla-docker/"><![CDATA[<p>This guide will walk you through the process of setting up the CARLA simulator (version 0.9.14) using Docker.</p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li>Docker installed on your system.</li> <li>NVIDIA Docker if you are using NVIDIA GPUs for rendering.</li> </ul> <h2 id="pull-the-carla-docker-image">Pull the CARLA Docker Image</h2> <p>Start by pulling the official CARLA image from Docker Hub:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull carlasim/carla:0.9.14
</code></pre></div></div> <h2 id="run-carla-in-a-docker-container">Run CARLA in a Docker Container</h2> <p>To run CARLA with Docker, you can use the following command. This setup forwards necessary ports and configures the environment for GPU usage and offscreen rendering:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>docker run <span class="nt">-p</span> 2000-2002:2000-2002 <span class="nt">--privileged</span> <span class="nt">--gpus</span> all <span class="nt">--net</span><span class="o">=</span>host <span class="nt">-v</span> /tmp/.X11-unix:/tmp/.X11-unix:rw carlasim/carla:0.9.14 /bin/bash ./CarlaUE4.sh <span class="nt">-RenderOffScreen</span>
</code></pre></div></div> <h2 id="installing-carla-and-its-python-api">Installing CARLA and its Python API</h2> <h3 id="installing-carla-on-debian-based-systems">Installing CARLA on Debian-based Systems</h3> <p>Debian packages of CARLA are available for both Ubuntu 18.04 (Bionic Beaver) and Ubuntu 20.04 (Focal Fossa). However, the officially supported version is Ubuntu 18.04. Here’s how to install CARLA using the Debian package repository:</p> <ol> <li> <p><strong>Add the CARLA Repository to Your System:</strong> This step involves adding the GPG key for the CARLA repository to your system and then adding the repository itself.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">sudo </span>apt-key adv <span class="nt">--keyserver</span> keyserver.ubuntu.com <span class="nt">--recv-keys</span> 1AF1527DE64CB8D9
 <span class="nb">sudo </span>add-apt-repository <span class="s2">"deb [arch=amd64] http://dist.carla.org/carla </span><span class="si">$(</span>lsb_release <span class="nt">-sc</span><span class="si">)</span><span class="s2"> main"</span>
</code></pre></div> </div> </li> <li> <p><strong>Install CARLA:</strong> Update your package list and install CARLA. The installation directory will be <code class="language-plaintext highlighter-rouge">/opt/carla-simulator/</code>.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">sudo </span>apt-get update
 <span class="nb">sudo </span>apt-get <span class="nb">install </span>carla-simulator
 <span class="nb">cd</span> /opt/carla-simulator
</code></pre></div> </div> </li> </ol> <h3 id="manual-installation-from-github">Manual Installation from GitHub</h3> <p>If the Debian server is down, as has been reported in issues like <a href="https://github.com/carla-simulator/carla/issues/7017">CARLA GitHub Issue #7017</a>, you can manually install CARLA:</p> <ol> <li> <p><strong>Install Required System Dependency:</strong> Before downloading CARLA, make sure that all necessary dependencies are installed.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">sudo </span>apt-get <span class="nt">-y</span> <span class="nb">install </span>libomp5
</code></pre></div> </div> </li> <li> <p><strong>Download CARLA Release:</strong> Use <code class="language-plaintext highlighter-rouge">wget</code> to download the CARLA release directly from its S3 bucket. Adjust the version number as needed for the specific version you are installing.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c"># Download CARLA version 0.9.14</span>
 wget https://carla-releases.s3.us-east-005.backblazeb2.com/Linux/CARLA_0.9.14.tar.gz
</code></pre></div> </div> </li> <li> <p><strong>Unpack CARLA:</strong> Unpack the downloaded archive to the desired directory, typically <code class="language-plaintext highlighter-rouge">/opt/carla-simulator/</code>.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">tar</span> <span class="nt">-xzvf</span> CARLA_0.9.14.tar.gz <span class="nt">-C</span> /opt/carla-simulator/
</code></pre></div> </div> </li> <li> <p><strong>Install the CARLA Python Module:</strong> Install the CARLA Python module and its dependencies to ensure that you can interact with CARLA using Python scripts.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c"># Ensure pip is up to date</span>
 pip <span class="nb">install</span> <span class="nt">--upgrade</span> pip
 <span class="c"># Install CARLA Python API</span>
 python <span class="nt">-m</span> pip <span class="nb">install </span><span class="nv">carla</span><span class="o">==</span>0.9.14
 <span class="c"># Install additional Python dependencies required for CARLA</span>
 python <span class="nt">-m</span> pip <span class="nb">install</span> <span class="nt">-r</span> /opt/carla-simulator/PythonAPI/examples/requirements.txt
</code></pre></div> </div> </li> </ol> <h2 id="check-the-server-is-running">Check the Server is Running</h2> <p>To verify the status of the CARLA server, there are several methods you can use to check if it is running properly:</p> <ol> <li> <p><strong>Check Container Processes</strong>: If you have launched the CARLA server in a Docker container, you can check the list of processes by running the <code class="language-plaintext highlighter-rouge">ps</code> command. In the command line of your container, enter the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ps aux | <span class="nb">grep </span>CarlaUE4
</code></pre></div> </div> <p>If the CARLA server is running, you should see a process listed that includes <code class="language-plaintext highlighter-rouge">CarlaUE4.sh</code> or a similar name.</p> </li> <li><strong>Check Log Output</strong>: The CARLA server typically outputs logs. If you start the server’s Docker container without running it in the background, you should be able to see the outputs directly in your terminal.</li> <li> <p><strong>Check Network Listening Ports</strong>: The CARLA server listens on specific ports by default (e.g., 2000-2002). On the host machine, you can use the following command to check if these ports are being listened to:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">sudo </span>netstat <span class="nt">-tulpn</span> | <span class="nb">grep </span>LISTEN
</code></pre></div> </div> <p>Look for ports <code class="language-plaintext highlighter-rouge">2000</code>, <code class="language-plaintext highlighter-rouge">2001</code>, and <code class="language-plaintext highlighter-rouge">2002</code> in the output to see if any process is bound to these ports. The output should be similar to:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> tcp        0      0 0.0.0.0:2001            0.0.0.0:<span class="k">*</span>               LISTEN      532651/CarlaUE4-Lin
 tcp        0      0 0.0.0.0:2000            0.0.0.0:<span class="k">*</span>               LISTEN      532651/CarlaUE4-Lin
 tcp        0      0 0.0.0.0:2002            0.0.0.0:<span class="k">*</span>               LISTEN      532651/CarlaUE4-Lin
</code></pre></div> </div> </li> <li> <p><strong>Testing Connection with CARLA Python API</strong>: If you have a Python environment set up with the CARLA Python client library, you can try writing a simple script to attempt a connection to the server:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kn">import</span> <span class="n">carla</span>

 <span class="k">try</span><span class="p">:</span>
     <span class="n">client</span> <span class="o">=</span> <span class="n">carla</span><span class="p">.</span><span class="nc">Client</span><span class="p">(</span><span class="sh">'</span><span class="s">localhost</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
     <span class="n">client</span><span class="p">.</span><span class="nf">set_timeout</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
     <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">CARLA server is running!</span><span class="sh">"</span><span class="p">)</span>
     <span class="c1"># Optionally, get some additional data
</span>     <span class="n">world</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">get_world</span><span class="p">()</span>
     <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Connected to world: </span><span class="sh">"</span><span class="p">,</span> <span class="n">world</span><span class="p">.</span><span class="nf">get_map</span><span class="p">().</span><span class="n">name</span><span class="p">)</span>
 <span class="k">except</span> <span class="nb">RuntimeError</span><span class="p">:</span>
     <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Cannot connect to CARLA server.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div> </div> <p>This script will attempt to connect to the CARLA server running locally on port 2000. If the connection is successful, it will print that the server is running.</p> </li> </ol> <h2 id="troubleshooting-common-errors">Troubleshooting Common Errors</h2> <p>When working with CARLA and Docker, you might encounter errors such as connection timeouts or ALSA audio issues. Below are some common errors.</p> <h3 id="connection-timeout">Connection Timeout</h3> <p>After running the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>nvidia-docker run <span class="nt">-p</span> 2000-2002:2000-2002 <span class="nt">-it</span> <span class="nt">--rm</span>  carlasim/carla:0.9.14 /bin/bash
<span class="nv">SDL_VIDEODRIVER</span><span class="o">=</span>offscreen ./CarlaUE4.sh <span class="nt">-opengl</span>
</code></pre></div></div> <p>Error Message:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cannot connect to CARLA server: time-out of 10000ms <span class="k">while </span>waiting <span class="k">for </span>the simulator, make sure the simulator is ready and connected to localhost:2000
</code></pre></div></div> <p>Solution:</p> <ul> <li>Ensure that the Docker container is running and the ports are correctly mapped.</li> <li> <p>Use the following command to check if CARLA is actively listening on the expected ports:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nb">sudo </span>netstat <span class="nt">-tulpn</span> | <span class="nb">grep </span>LISTEN
</code></pre></div> </div> </li> </ul> <h3 id="alsa-audio-errors">ALSA Audio Errors</h3> <p>When running CARLA, you might see repeated ALSA errors. These generally indicate missing audio configurations, which are common in Docker containers but don’t affect the simulation:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>carla_0914_env<span class="o">)</span> <span class="o">(</span>base<span class="o">)</span> Procuda% docker run <span class="nt">-e</span> <span class="nv">DISPLAY</span><span class="o">=</span><span class="nv">$DISPLAY</span> <span class="nt">-it</span> <span class="nt">--net</span><span class="o">=</span>host <span class="nt">--gpus</span> all carlasim/carla:0.9.14 /bin/bash ./CarlaUE4.sh <span class="nt">-opengl</span> <span class="nt">-world-port</span><span class="o">=</span>2000 <span class="nt">-RenderOffScreen</span>
4.26.2-0+++UE4+Release-4.26 522 0
Disabling core dumps.
sh: 1: xdg-user-dir: not found
ALSA lib confmisc.c:767:<span class="o">(</span>parse_card<span class="o">)</span> cannot find card <span class="s1">'0'</span>
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_card_driver returned error: No such file or directory
ALSA lib confmisc.c:392:<span class="o">(</span>snd_func_concat<span class="o">)</span> error evaluating strings
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1246:<span class="o">(</span>snd_func_refer<span class="o">)</span> error evaluating name
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5007:<span class="o">(</span>snd_config_expand<span class="o">)</span> Evaluate error: No such file or directory
ALSA lib pcm.c:2495:<span class="o">(</span>snd_pcm_open_noupdate<span class="o">)</span> Unknown PCM default
ALSA lib confmisc.c:767:<span class="o">(</span>parse_card<span class="o">)</span> cannot find card <span class="s1">'0'</span>
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_card_driver returned error: No such file or directory
ALSA lib confmisc.c:392:<span class="o">(</span>snd_func_concat<span class="o">)</span> error evaluating strings
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1246:<span class="o">(</span>snd_func_refer<span class="o">)</span> error evaluating name
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5007:<span class="o">(</span>snd_config_expand<span class="o">)</span> Evaluate error: No such file or directory
ALSA lib pcm.c:2495:<span class="o">(</span>snd_pcm_open_noupdate<span class="o">)</span> Unknown PCM default
ALSA lib confmisc.c:767:<span class="o">(</span>parse_card<span class="o">)</span> cannot find card <span class="s1">'0'</span>
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_card_driver returned error: No such file or directory
ALSA lib confmisc.c:392:<span class="o">(</span>snd_func_concat<span class="o">)</span> error evaluating strings
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1246:<span class="o">(</span>snd_func_refer<span class="o">)</span> error evaluating name
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5007:<span class="o">(</span>snd_config_expand<span class="o">)</span> Evaluate error: No such file or directory
ALSA lib pcm.c:2495:<span class="o">(</span>snd_pcm_open_noupdate<span class="o">)</span> Unknown PCM default
ALSA lib confmisc.c:767:<span class="o">(</span>parse_card<span class="o">)</span> cannot find card <span class="s1">'0'</span>
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_card_driver returned error: No such file or directory
ALSA lib confmisc.c:392:<span class="o">(</span>snd_func_concat<span class="o">)</span> error evaluating strings
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_concat returned error: No such file or directory
ALSA lib confmisc.c:1246:<span class="o">(</span>snd_func_refer<span class="o">)</span> error evaluating name
ALSA lib conf.c:4528:<span class="o">(</span>_snd_config_evaluate<span class="o">)</span> <span class="k">function </span>snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5007:<span class="o">(</span>snd_config_expand<span class="o">)</span> Evaluate error: No such file or directory
ALSA lib pcm.c:2495:<span class="o">(</span>snd_pcm_open_noupdate<span class="o">)</span> Unknown PCM default
</code></pre></div></div> <h3 id="xdg-user-dir-not-found-error">“xdg-user-dir: not found” Error</h3> <p>When running CARLA, especially in Docker environments, you might encounter the <code class="language-plaintext highlighter-rouge">xdg-user-dir: not found</code> error. This error typically occurs because the <code class="language-plaintext highlighter-rouge">xdg-user-dirs</code> package, which is responsible for managing user directories like Downloads, Desktop, etc., is not installed or accessible in the container. While this error generally does not impact the functionality of CARLA if you’re not using these directories (see <a href="https://github.com/carla-simulator/carla/issues/3514">this issue</a>).</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Tutorials"/><summary type="html"><![CDATA[This guide will walk you through the process of setting up the CARLA simulator (version 0.9.14) using Docker.]]></summary></entry><entry><title type="html">Coding week1 5/27-6/02</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week1-5-27-6-02/" rel="alternate" type="text/html" title="Coding week1 5/27-6/02"/><published>2024-06-10T00:00:00+00:00</published><updated>2024-06-10T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/week1</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/coding-week1-5-27-6-02/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>In this week’s meeting, we reviewed the project’s current progress. I updated the project blog and asked for feedback. I have successfully set up CARLA on Docker, with plans to transition to a physical machine soon, and I will post a Docker installation tutorial later. We discussed several technical issues, including dependencies and model loading errors, and discussed data collection script problems in relation to graphical mode and ROS Bridge compatibility.</p> <p>Open issues on GitHub were reviewed, with a particular note on the need to make a PR and future plans for Docker installation. During the open floor discussion, the team discussed the potential for reproducibility and future enhancements similar to the LMdrive model. Concerns about GPU resources and API token support from Google were raised, with plans to inquire further.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="to-do-list">To-Do List</h3> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Check dependencies and model loading error</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Conduct a literature review about the potential direction</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>A CARLA docker installation documentation</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Inquiry about potential GPU resources and API token support</li> </ul> <h3 id="following-previous-issues"><strong>Following previous issues</strong></h3> <p>Following previous issues: <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/2">issue1</a> and <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/3">issue2</a>, the model’s issues were resolved by changing the number of outputs, and the environment dependency issues have also been resolved. However, there are still problems with the current data collection, but an issue has not yet been raised; it is still being checked. The current data collection scripts may encounter errors or pauses, which could require manual intervention or result in delays in data collection. There are several solutions currently available:</p> <ol> <li>Use a physical machine to set up checks for cameras, etc., in a graphical interface.</li> <li>LMDrive has provided some scripts for data collection that can be tested and explored.</li> </ol> <h3 id="literature-review"><strong>Literature review</strong></h3> <h4 id="modules">Modules</h4> <p>The architectural framework of world models is structured to facilitate complex decision-making processes that closely emulate human cognitive functions. These models are comprised of several distinct but interconnected modules, each serving a crucial role in the system’s overall performance and capability:</p> <ul> <li><strong>Perception:</strong> This module serves as the interface between the external environment and the model, capturing multi-modal sensory inputs such as images, sounds, and tactile feedback. By transforming raw sensory data into a more digestible and actionable format, this module ensures that the model is well-equipped to respond to the complexities of its surroundings. It leverages advanced sensory technologies and encoding mechanisms. This module is adept not only at recognizing objects or scenes but also at interpreting the structural and contextual relationships within the sensory information. This precise environmental understanding forms the foundation for all subsequent data-driven decision-making processes.</li> <li><strong>Memory Module:</strong> This module serves a role akin to the human hippocampus, crucial for encoding, storing, and retrieving information from past and present environmental interactions. It supports both short-term and long-term memory functionalities. Short-term memory processes immediate tasks—such as remembering specific details of a traffic intersection, while long-term memory retains the outcomes of particular events or the efficacy of complex strategies over time. By managing a dynamic repository of experiences, this module enables continuous learning and adaptation, which are indispensable for responding to evolving challenges.</li> <li><strong>Action Module:</strong> This module operates based on the information processed by the Perception and Modules to formulate and execute decisions. It evaluates the current conditions along with forward-looking predictions to develop actions aimed at achieving specific objectives, such as optimizing resource use or maximizing operational efficacy. Typically, this process relies on RL, aiming to maximize rewards. The capability of this module to integrate information and implement strategic decisions is crucial for responsive interactions with the environment, ensuring that the system can adapt to changes effectively and execute tasks efficiently.</li> <li><strong>World Model Module:</strong> Situated at the heart of the system’s architecture, its primary function is to refine and enhance the system’s understanding of the environment by generating comprehensive simulations. Through these simulations, the module projects future environmental conditions, providing a foresight that is critical for strategic planning. This predictive capability allows the system to prepare for potential scenarios, offering a degree of anticipatory adaptation and flexibility.</li> </ul> <p>These modules form an integrated framework that enables world models to simulate human-like cognitive processes and decision-making. This module structure not only enhances the operational capabilities of such systems but also contributes to their ability to operate independently and efficiently in a variety of real-world applications.</p> <h4 id="architectures">Architectures</h4> <p>The architecture of world models is designed to predict future states of environments by balancing deterministic forecasts with the uncertainty of real-world dynamics. In high-dimensional sensory input scenarios, the challenge lies in efficiently representing observed information through latent dynamical models to make compact and accurate predictions. To manage these complexities, a variety of architectures have been proposed, including the RSSM and the JEPA, as well as Transformer-based architecture.</p> <ul> <li><strong>RSSM:</strong> The RSSM stands at the forefront of this architectural evolution, designed to efficiently navigate and predict within latent spaces. By decomposing the latent state into deterministic and stochastic elements, RSSM manages the unpredictable nature of real-world environments. This model excels in continuous control tasks by learning dynamic environmental models from sensory data like pixels and formulating action plans within the encoded latent space. The RSSM features a dual-path architecture where its deterministic components provide stability and its stochastic components enhance adaptability. This structure makes RSSM ideal for scenarios that require robust yet flexible predictive capabilities.</li> <li><strong>JEPA:</strong> JEPA revolutionizes predictive modelling by focusing on a higher-level representation space rather than traditional pixel-level output generation. The architecture’s predictive process involves generating and utilizing latent variables to fill in gaps or predict missing elements in the input data. This architecture marks a paradigm shift by abstracting inputs and targets through dual encoders into representations and leveraging a latent variable for prediction. JEPA excels in filtering out noise and irrelevancies, concentrating on essential data elements. Its use of self-supervised learning enables pre-training on unlabeled datasets, refining predictive accuracy for both visual and non-visual tasks.</li> <li><strong>Transformer-based Architecture:</strong> Leveraging the attention mechanism inherent in Transformer architectures, these models provide a framework for handling memory-intensive tasks. Transformer-based world models like the Spatial Temporal Patchwise Transformer (STPT) and the Transformer State Space Model (TSSM) focus on different segments of input data simultaneously. These models excel at managing intricate temporal and spatial dependencies. This capability enables effective management and prediction of dynamic environmental interactions through their advanced memory access and dependency tracking.</li> </ul> <p><em>Please note that there is also a section of review content that will be part of a paper to be submitted and will be expected to make public next week.</em></p> <h2 id="gpu-resource">GPU resource</h2> <p>Assessing the risks, it’s clear that we should rely on external sources like university clusters, especially when I need consistent access to high-performance GPUs such as the NVIDIA A100. But I’ve faced challenges with availability. While I can access 30 series and A4000 GPUs, I’m also exploring potential access through a university cluster. Unfortunately, GSOC has confirmed they cannot provide my GPU resources. I’m also considering GPU resources from the University of Edinburgh, though this might require queuing for access. Sergio mentioned that we have access to a powerful GPU cluster at his university, and they might give me access when needed.</p> <h2 id="docker-installation">Docker installation</h2> <p>We have updated the step-by-step tutorial for installing CARLA based on Docker. Unlike the official website, this version includes more detailed troubleshooting steps. More details can be find in this <a href="/gsoc2024-ZebinHuang/blog/2024/carla-docker/">post</a>.</p>]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Weekly Meeting]]></summary></entry><entry><title type="html">Bonding 5/21 - 5/27</title><link href="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-21-5-27/" rel="alternate" type="text/html" title="Bonding 5/21 - 5/27"/><published>2024-05-26T00:00:00+00:00</published><updated>2024-05-26T00:00:00+00:00</updated><id>https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding</id><content type="html" xml:base="https://theroboticsclub.github.io/gsoc2024-ZebinHuang/blog/2024/community-bonding-5-21-5-27/"><![CDATA[<h3 id="weekly-meeting">Weekly Meeting</h3> <p>During the May 20, 2024, we discussed beginning the project by replicating last year’s model using a simple LLM for handling different input commands and gradually progressing towards more complex models. Key tasks for moving forward include conducting a literature review to define the project’s specific research question, setting up necessary tools like CARLA and behavior metrics, and addressing technical setup challenges.</p> <p>More details can be found here: <a href="https://docs.google.com/document/d/1b2ZEU5Gt8gP2ae_YzNSJSd7RukUrsG_aDJFLnbvoQiM/edit">Google Doc</a></p> <h3 id="to-do-list-during-the-bonding-period">To-Do List during the bonding period</h3> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up a blog based on examples from previous years.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Set up CARLA.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Run Qi’s models.</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Read and analyze literature on autonomous driving and LLMs.</li> </ul> <h3 id="code-replication"><strong>Code Replication</strong></h3> <p>This week, I attempted to replicate certain elements of the project codebase <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao">Meiqizhao’s code</a> and encountered some challenges that required raising issues for resolution. Specifically, I opened two issues <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/2">issue1</a> <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/issues/3">issue2</a> and <a href="https://github.com/TheRoboticsClub/gsoc2023-Meiqi_Zhao/pull/4">one PR</a> regarding bugs found during the replication process. To enhance reproducibility, I am currently working with Docker, and I also plan to provide a Docker branch later on.</p> <h3 id="behavior-metrics-exploration"><strong>Behavior Metrics Exploration</strong></h3> <p>I reviewed the <a href="https://github.com/JdeRobot/BehaviorMetrics">Behaviour Metrics</a> repos and related papers. The Behavior Metrics can provide a structured framework for quantifying the effectiveness and performance of autonomous system in simulated scenarios. Incorporating text input for autonomous driving guidance enhances the Behavior Metrics benchmark by interactivity and interpretability. Here are some potential integration methods and benefits:</p> <ol> <li><strong>Expanded Testing Scenarios</strong>: It enables the creation of a broader range of test environments and situations that include verbal commands and interactions.</li> <li><strong>Enhanced Textual Interpretability</strong>: Provides clarity on how the system interprets and responds to natural language inputs, which improves the system’s transparency and trustworthiness.</li> <li><strong>Adapted Interaction Methods</strong>: Allows for modifications in user interaction, offering more intuitive and accessible ways for users to communicate with autonomous systems.</li> </ol> <h3 id="literature-review-and-feasibility-analysis"><strong>Literature Review and Feasibility Analysis</strong></h3> <p>I conducted a review on research papers related to our project. The focus was on assessing the feasibility of replicating the studies, considering factors like data availability, computational requirements, and whether the methods are open-source. Such analysis helps in understanding the practical aspects of implementing these research findings in our work.</p> <table> <thead> <tr> <th>Paper Title</th> <th>Reproducibility</th> <th>Data Volume</th> <th>Technical Difficulty</th> <th>GPU Requirements</th> </tr> </thead> <tbody> <tr> <td>GPT-4V Takes the Wheel <d-cite key="huangGPT4VTakesWheel2024a"></d-cite></td> <td>Low: Uses publicly available datasets. <span style="color:red;">Not open-sourced</span></td> <td>JAAD, WiDEVIEW</td> <td>High: Integrates vision and language models for dynamic behavior prediction</td> <td>High: VLM processing but not illustrated</td> </tr> <tr> <td>Driving with LLMs <d-cite key="chenDrivingLLMsFusing2023a"></d-cite></td> <td>Low: New dataset and unique architecture, reproducibility <a href="https://github.com/wayveai/Driving-with-LLMs">GitHub</a></td> <td>Custom 160k QA pairs, 10k driving scenario. Which simulator?</td> <td>Very High: Novel fusion of vector modalities and LLMs</td> <td>Moderate: Minimum of 20GB VRAM for running evaluations, Minimum of 40GB VRAM for training</td> </tr> <tr> <td>LMDrive <d-cite key="shaoLMDriveClosedLoopEndtoEnd2023a"></d-cite></td> <td>High: Dataset and models are open-sourced, but complexity in GPU setup</td> <td><span style="color:green;">64K parsed clips and 464K notice instructions</span></td> <td>Very High: Real-time, closed-loop control with LLMs in vehicles</td> <td><span style="color:red;">Very High: 2~3 days for the visual encoder on 8x A100 (80G)</span></td> </tr> <tr> <td>Language Models as Trajectory Generators <d-cite key="kwonLanguageModelsZeroShot2023"></d-cite></td> <td>High: Standard dataset, clear methodology and evaluation process</td> <td>Flexible data generation with Pybullet</td> <td>Moderate: Focus on trajectory generation using LLMs, less complex than real-time control systems</td> <td>Low: Less demanding compared to real-time visual tasks</td> </tr> </tbody> </table> <p></p> <p>Here is a summary of the preliminary analysis of different literature pieces:</p> <ol> <li><strong>GPT-4V Takes the Wheel</strong>: This work utilizes publicly available datasets but is not open-sourced, which poses a significant barrier to reproducibility. Although it can serve as a conceptual reference, the lack of open access means it cannot be directly replicated.</li> <li><strong>Driving with LLMs</strong>: The source code is open. However, the simulator used is proprietary to Wayve, restricting access and thus full replication of the project. While the architecture and approach can be studied.</li> <li><strong>LMDrive</strong>: This project appears the most promising in terms of openness and practical usability. It is conducted on the Carla simulator platform, and pre-trained models along with the dataset are provided. Although there are no current reproducibility issues or bugs reported, the main challenge is the significant computational requirement—training requires eight A100 GPUs (80GB each). Initial testing might focus on evaluating the provided pre-trained models due to these resource demands.</li> <li><strong>Language Models as Trajectory Generators</strong>: This work offers a unique perspective by using zero-shot methods in manipulators, which is the least resource-intensive approach among the ones listed. However, for real-time systems like autonomous driving, this approach would need to incorporate more robust and safer control mechanisms to ensure reliability and safety in dynamic environments.</li> </ol> <p>From the feasibility standpoint, some of the literature reviewed indicated very high resource requirements, such as one paper necessitating 8 * A100 GPUs. These are substantial resource demands that pose challenges for replication.</p> <p>The core question we need to address is: What is our objective? If the goal is to replicate existing solutions and integration, we need to identify the features and MVP. However, if our aim is to optimize, the biggest hurdle is the training phase, particularly the GPU bottlenecks during this process. This will need to be discussed further in next week’s meeting.</p> <h3 id="moving-forward"><strong>Moving Forward</strong></h3> <p>Understanding these resource limitations and objectives will help guide our project’s direction. Our next steps involve deciding whether to seek resource optimization or to focus on adapting our goals to fit the available computational resources. Additionally, we are currently addressing several issues and plan to conduct further literature research to deepen my understanding of the field.</p> ]]></content><author><name>Zebin Huang</name></author><category term="gsoc-2024"/><category term="Weekly_blogs"/><summary type="html"><![CDATA[Analysis of code replication and literature review]]></summary></entry></feed>